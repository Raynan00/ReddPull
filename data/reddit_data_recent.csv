id,title,selftext,url,author,score,created_utc,num_comments,permalink,flair,publish_date
1laipn1,[Project] I built an open-source tool to turn handwriting into a font using PyTorch and OpenCV.,"I'm excited to share HandFonted, a project I built that uses a Python-powered backend to convert a photo of handwriting into an installable .ttf font file.  **Live Demo:** [https://handfonted.xyz](https://www.google.com/url?sa=E&q=https%3A%2F%2Fhandfonted.xyz)   **GitHub Repo:** [https://github.com/reshamgaire/HandFonted](https://github.com/reshamgaire/HandFonted)  **What My Project Does**  HandFonted is a web application that allows a user to upload a single image of their handwritten alphabet. The backend processes this image, isolates each character, identifies it using a machine learning model, and then generates a fully functional font file (.ttf) that the user can download and install on their computer.  **Target Audience**  This is primarily a portfolio project to demonstrate a full-stack application combining computer vision, ML, and web development. It's meant for:  * **Developers and students** to explore how these different technologies can be integrated. * **Hobbyists and creatives** who want a fun, free tool to create a personal font without the complexity of professional software.  **How it Differs from Alternatives**  While there are commercial services like Calligraphr, HandFonted differs in a few key ways:  * **No Template Required:** You can write on any plain piece of paper, whereas many alternatives require you to print and fill out a specific template. * **Fully Free & Open-Source:** There are no premium features or sign-ups. The entire codebase is available on GitHub for anyone to inspect, use, or learn from. * **AI-Powered Recognition:** It uses a custom PyTorch model for classification, making it more of a tech demo than a simple image-tracing tool.  **Technical Walkthrough**  The pipeline is entirely Python-based:  1. **Segmentation (OpenCV):** The backend uses an OpenCV pipeline with adaptive thresholding and contour detection to isolate each character. I also added a heuristic to merge dots with their 'i' and 'j' bodies. 2. **Classification (PyTorch):** Each character image is fed into a custom CNN (a lightweight ResNet/Inception hybrid) for identification. I use scipy.optimize.linear\_sum\_assignment to find the optimal one-to-one mapping between the input images and the 52 possible characters. 3. **Font Generation (fontTools & skimage):** The classified image is vectorized using skimage (skeletonization -> distance transform -> contour tracing). The fontTools library then programmatically builds the .ttf file by inserting these new vector glyphs into a base font template and updating its metrics.  I'd love any feedback or questions you have about the implementation. Thanks for checking it out",https://www.reddit.com/r/Python/comments/1laipn1/project_i_built_an_opensource_tool_to_turn/,Educational_Pea_5027,0,1749828176.0,0,/r/Python/comments/1laipn1/project_i_built_an_opensource_tool_to_turn/,Showcase,2025-06-13 16:22:56
1laieu5,True HDR video maker,"I have made a true SDR to HDR video maker in python and compiled it to exe for everyone, It makes and injects HDR metadata into the video and you have different tone mapping options. [https://drive.google.com/file/d/1o5kWiKzZbgtNQ\_oht8DS6Rpcjn1jtDl3/view?usp=sharing](https://drive.google.com/file/d/1o5kWiKzZbgtNQ_oht8DS6Rpcjn1jtDl3/view?usp=sharing)",https://www.reddit.com/r/Python/comments/1laieu5/true_hdr_video_maker/,Intrepid-Carpet-3005,0,1749827467.0,3,/r/Python/comments/1laieu5/true_hdr_video_maker/,Resource,2025-06-13 16:11:07
1lafr6s,Anyway to write polars with less code ??,"# Hi fellow polars users  i'm looking for good tips on polars  Recently found a way to write less code  :  `df.filter(pl.col(""size"") = 12)`  \-> `df.filter(size=12)`  Any ideas for other filters, i think pl.col()... is too much 😄      df.filter(pl.col(""value"").is_in(values))     df.filter(pl.col(""value"")>=10)",https://www.reddit.com/r/Python/comments/1lafr6s/anyway_to_write_polars_with_less_code/,Particular-Goat-7579,2,1749820809.0,10,/r/Python/comments/1lafr6s/anyway_to_write_polars_with_less_code/,Discussion,2025-06-13 14:20:09
1laf5ss,Pypp: A Python to C++ transpiler [WIP]. Gauging interest and open to advice.,"I am trying to gauge interest in this project, and I am also open to any advice people want to give. Here is the project github: [https://github.com/curtispuetz/pypp](https://github.com/curtispuetz/pypp)  # Pypp (a Python to C++ transpiler)  This project is a work-in-progress. Below you will find sections: The goal, The idea (What My Project Does), How is this possible?, The inspiration (Target Audience), Why not cython, pypy, or Nuitka? (Comparison), and What works today?  ## The goal  The primary goal of this project is to make the end-product of your Python projects execute faster.  ## What My Project Does  The idea is to transpile your Python project into a C++ cmake project, which can be built and executed much faster, as C/C++ is the fastest high-level language of today.  You will be able to run your code either with the Python interpreter, or by transpiling it to C++ and then building it with cmake. The steps will be something like this:  1. install pypp  2. setup your project with cmd: \`pypp init\`  3. install any dependencies you want with cmd: \`pypp install \[name\]\` (e.g. pypp install numpy)  4. run your code with the python interpreter with cmd: \`python my\_file.py\`  5. transpile your code to C++ with cmd: \`pypp transpile\`   6. build the C++ code with cmake commands  Furthermore, the transpiling will work in a way such that you will easily be able to recognize your Python code if you look at the transpiled C++ code. What I mean by that is all your Python modules will have a corresponding .h file and, if needed, a corresponding .cpp file in the same directory structure, and all names and structure of the Python code will be preserved in the C++. Effectively, the C++ transpiled code will be as close as possible to the Python code you write, but just in C++ rather than Python.   Your project will consist of two folders in the root, one named python where the Python code you write will go, and one named cpp where the transpiled C++ code will go.  ### But how is this possible?  You are probably thinking: how is this possible, since Python code does not always have a direct C++ equivalent?  The key to making it possible is that not all Python code will be compatible with pypp. This means that in order to use pypp you will need to write your Python code in a certain way (but it will still all be valid Python code that can be run with the Python interpreter, which is unlike Cython where you can write code which is no longer valid Python).  Here are some of the bigger things you will need to do in your Python code (not a complete list; the complete list will come later):  - Include type annotations for all variables, function/method parameters, and function/method return types.  - Not use the Python None keyword, and instead use a PyppOptional which you can import.  - Not use my\_tup\[0\] to access tuple elements, and instead use pypp\_tg(my\_tup, 0) (where you import pypp\_tg)  - You will need to be aware that in the transpiled C++ every object is passed as a reference or constant reference, so you will need to write your Python so that references are kept to these objects because otherwise there will be a bug in your transpiled C++ (this will be unintuitive to Python programmers and I think the biggest learning point or gotcha of pypp. I hope most other adjustments will be simple and i'll try to make it so.)  Another trick I have employed so far, that is probably worthy of note here, is in order to translate something like a python string or list to C++ I have implemented PyStr and PyList classes in C++ with identical as possible methods to the python string and list types, which will be used in the C++ transpiled code. This makes transpiling Python to C++ for the types much easier.  ## Target Audience  My primary inspiration for building this is to use it for the indie video game I am currently making.  For that game I am not using a game engine and instead writing my own engine (as people say) in OpenGL. For writing video game code I found writing in Python with PyOpenGL to be much easier and faster for me than writing it in C++. I also got a long way with Python code for my game, but now I am at the point where I want more speed.  So, I think this project could be useful for game engine or video game development! Especially if this project starts supporting openGL, vulkan, etc.  Another inspiration is that when I was doing physics/math calculations/simulations in Python in my years in university, it would have been very helpful to be able to transpile to C++ for those calculations that took multiple days running in Python.  ## Comparison  Why build pypp when you can use something similar like cython, pypy, or Nuitka, etc. that speeds up your python code?   Because from research I have found that these programs, while they do improve speed, do not typically reach the C++ level of speed. pypp should reach C++ level of speed because the executable built is literally from C++ code.  For cython, I mentioned briefly earlier, I don't like that some of the code you would write for it is no longer valid Python code. I think it would be useful to have two options to run your code (one compiled and one interpreted).  I think it will be useful to see the literal translation of your Python code to C++ code. On a personal note, I am interested in how that mapping can work.  ## What works today?  What works currently is most of functions, if-else statements, numbers/math, strings, lists, sets, and dicts. For a more complete picture of what works currently and how it works, take a look at the test\_dir where there is a python directory and a cpp directory containing the C++ code transpiled from the python directory. ",https://www.reddit.com/r/Python/comments/1laf5ss/pypp_a_python_to_c_transpiler_wip_gauging/,joeblow2322,19,1749819167.0,20,/r/Python/comments/1laf5ss/pypp_a_python_to_c_transpiler_wip_gauging/,Showcase,2025-06-13 13:52:47
1ladu54,NexFace: High Quality Face Swap to Image and Video,"I've been having some issues with some of popular faceswap extensions on comfy and A1111 so I created NexFace is a Python-based desktop app that generates high quality face swapped images and videos. NexFace is an extension of Face2Face and is based upon insight face. I have added image enhancements in pre and post processing and some facial upscaling. This model is unrestricted and I have had some reluctance to post this as I have seen a number of faceswap repos deleted and accounts banned but ultimately I beleive that it's up to each individual to act in accordance with the law and their own ethics.  Local Processing: Everything runs on your machine - no cloud uploads, no privacy concerns High-Quality Results: Uses Insightface's face detection + custom preprocessing pipeline Batch Processing: Swap faces across hundreds of images/videos in one go Video Support: Full video processing with audio preservation Memory Efficient: Automatic GPU cleanup and garbage collection Technical Stack Python 3.7+ Face2Face library OpenCV + PyTorch Gradio for the UI FFmpeg for video processing Requirements 5GB RAM minimum GPU with 8GB+ VRAM recommended (but works on CPU) FFmpeg for video support  I'd love some feedback and feature requests. Let me know if you have any questions about the implementation.  https://github.com/ExoFi-Labs/Nexface/  * [Image Sample 1](https://i.imgur.com/w1pmVY2.png)  * [Image Sample 2](https://i.imgur.com/dnNwook.png)",https://www.reddit.com/r/Python/comments/1ladu54/nexface_high_quality_face_swap_to_image_and_video/,typhoon90,1,1749815149.0,0,/r/Python/comments/1ladu54/nexface_high_quality_face_swap_to_image_and_video/,Resource,2025-06-13 12:45:49
1laazsd,Recent Noteworthy Package Releases,"Over the last 7 days, I've noticed these significant upgrades in the Python package ecosystem.  [**NumPy 2.3.0**](https://github.com/numpy/numpy/releases/tag/v2.3.0)  [**google-adk 1.3.0**](https://github.com/google/adk-python/releases/tag/v1.3.0)  [**pip-system-certs 5.0**](https://gitlab.com/alelec/pip-system-certs/-/commits/v5.0)  [**django-multiselectfield 1.0.0**](https://github.com/goinnn/django-multiselectfield/releases/tag/v1.0.0)  [**shap 0.48.0**](https://github.com/shap/shap/releases/tag/v0.48.0)  [**django-waffle 5.0.0**](https://github.com/django-waffle/django-waffle/releases/tag/v5.0.0)  [**schemathesis 4.0.0**](https://github.com/schemathesis/schemathesis/releases/tag/v4.0.0)",https://www.reddit.com/r/Python/comments/1laazsd/recent_noteworthy_package_releases/,ashok_tankala,5,1749804424.0,0,/r/Python/comments/1laazsd/recent_noteworthy_package_releases/,News,2025-06-13 09:47:04
1la4yvk,SQLAlchemy just the core - but improved - for no-ORM folks,"Project: https://github.com/sayanarijit/sqla-fancy-core  What my project does:  There are plenty of ORMs to choose from in Python world, but not many sql query makers for folks who prefer to stay close to the original SQL syntax, without sacrificing security and code readability. The closest, most mature and most flexible query maker you can find is SQLAlchemy core.  But the syntax of defining tables and making queries has a lot of scope for improvement. For example, the table.c.column syntax is too dynamic, unreadable, and probably has performance impact too. It also doesn’t play along with static type checkers and linting tools.  So here I present one attempt at getting the best out of SQLAlchemy core by changing the way we define tables.  The table factory class it exposes, helps define tables in a way that eliminates the above drawbacks. Moreover, you can subclass it to add your preferred global defaults for columns (e.g. not null as default). Or specify custom column types with consistent naming (e.g. created_at).  Target audience:  Production. For folks who prefer query maker over ORM.  Comparison with other projects:  Piccolo: Tight integration with drivers. Very opinionated. Not as flexible or mature as sqlalchemy core.  Pypika: Doesn’t prevent sql injection by default. Hence can be considered insecure.  Raw queries as strings with placeholder: sacrifices code readability, and prone to sql injection if one forgets to use placeholders.  Other ORMs: They are ORMs, not query makers.",https://www.reddit.com/r/Python/comments/1la4yvk/sqlalchemy_just_the_core_but_improved_for_noorm/,NeverMindMyPresence,31,1749782050.0,2,/r/Python/comments/1la4yvk/sqlalchemy_just_the_core_but_improved_for_noorm/,Showcase,2025-06-13 03:34:10
1la3n57,Built a video on creating a free AI agent for beginners ( Open source and Free to Try)!,"Hey folks! 👋  Over the past few weeks, I’ve been experimenting with building a lightweight AI assistant using only free tools — no OpenAI key required. I wanted to share this as both a learning project and a useful tool you can run yourself.  🎥 I've also created a comprehensive, step-by-step tutorial on how to build this agent, including all the code, prompts, and logic. It's super beginner-friendly, so if you’re new to AI agents, this could be a great place to start!  📺 Watch the tutorial here: [https://youtu.be/UjhSpqqOza8?si=MBTYryawlgyV2rP5](https://youtu.be/UjhSpqqOza8?si=MBTYryawlgyV2rP5)  👉 Build Your First AI Agent with Python + LLaMA  💻 GitHub Repo:  👉 [https://github.com/jigs074/AI-assistant-Autonomous-AI-agent-.git](https://github.com/jigs074/AI-assistant-Autonomous-AI-agent-.git)  🔧 What it does:  Take natural language commands (via CLI or Streamlit)  Perform real tasks like:  Web search  Sending emails  Summarizing content  Opening files/apps  Built with LLaMA 3 (via Groq API), no paid APIs  I’d love to get your thoughts, feedback, or ideas for what I should add next — maybe local RAG or voice support?  Please let me know if you find this helpful or if you'd like to build your own version!  Cheers,  Jignesh  👨‍💻 [My Youtube Channel](https://www.youtube.com/@JigCode) (posting practical AI/ML dev tutorials)",https://www.reddit.com/r/Python/comments/1la3n57/built_a_video_on_creating_a_free_ai_agent_for/,Powerful-Ad7836,0,1749777947.0,6,/r/Python/comments/1la3n57/built_a_video_on_creating_a_free_ai_agent_for/,Tutorial,2025-06-13 02:25:47
1la1w5g,Friday Daily Thread: r/Python Meta and Free-Talk Fridays,"# Weekly Thread: Meta Discussions and Free Talk Friday 🎙️  Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related!  ## How it Works:  1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community. 2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community. 3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting.  ## Guidelines:  * All topics should be related to Python or the /r/python community. * Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy).  ## Example Topics:  1. **New Python Release**: What do you think about the new features in Python 3.11? 2. **Community Events**: Any Python meetups or webinars coming up? 3. **Learning Resources**: Found a great Python tutorial? Share it here! 4. **Job Market**: How has Python impacted your career? 5. **Hot Takes**: Got a controversial Python opinion? Let's hear it! 6. **Community Ideas**: Something you'd like to see us do? tell us.  Let's keep the conversation going. Happy discussing! 🌟",https://www.reddit.com/r/Python/comments/1la1w5g/friday_daily_thread_rpython_meta_and_freetalk/,AutoModerator,2,1749772834.0,1,/r/Python/comments/1la1w5g/friday_daily_thread_rpython_meta_and_freetalk/,:pythonLogo: Daily Thread,2025-06-13 01:00:34
1l9urle,"Website version of Christopher Manson's 1985 puzzle book, ""Maze""","This out of print book was from before my time, but *Maze: Solve the World's Most Challenging Puzzle* by Christopher Manson was a sort of choose-your-own-adventure book that had a $10,000 prize for whoever solved it first. (No one did; the prize was eventually split up among twelve people who got the closest.)  I created a modern, mobile-friendly web version of the book.  GitHub (with Python source): https://github.com/asweigart/mazewebsite  Website: https://inventwithpython.com/mazewebsite/  Start of the maze: https://inventwithpython.com/mazewebsite/directions.html  There are 45 ""rooms"" in the maze. I created HTML image maps and gathered the text descriptions into a throwaway Python script that generates the html files for the maze. I didn't want it to rely on a database or backend, just HTML, CSS, and a little Bootstrap to make it mobile-friendly. The Python code is in the git repo.  ## What My Project Does  Generates HTML files for a web version of Christopher Manson's 1985 puzzle book, ""Maze""  ## Target Audience  Anyone can view the output website. The Python code may be of interest to people who have similar one-off projects.  ## Comparison  The throwaway script spits out html files, making it easy for me to make updates to all 45 pages at once. It's a one-off project that doesn't use other modules, so it's not supposed to be a web framework like Flask or Django or anything.",https://www.reddit.com/r/Python/comments/1l9urle/website_version_of_christopher_mansons_1985/,AlSweigart,84,1749754758.0,3,/r/Python/comments/1l9urle/website_version_of_christopher_mansons_1985/,Showcase,2025-06-12 19:59:18
1l9re6v,Productivity Tracker CLI,Hi there!  I've completed a project recently that I would like to share. It is a productivity tracker that allows you to record how much time you spend working on something. Here is a link to it [https://github.com/tossik8/tracker](https://github.com/tossik8/tracker).  I made this project because I wanted to improve my time management. Feel free to leave your feedback and I hope some of you find it useful as well!,https://www.reddit.com/r/Python/comments/1l9re6v/productivity_tracker_cli/,EstimateConfident492,12,1749746923.0,6,/r/Python/comments/1l9re6v/productivity_tracker_cli/,Resource,2025-06-12 17:48:43
1l9q16q,I built a fullstack solopreneur project template with free cloud hosting and detailed tutorials,"Hey everyone,   I’ve been working on a fullstack template aimed at solo devs or indie hackers who want to build and ship something without spending money on infrastructure. I put a lot of effort into making sure everything works out of the box and included step-by-step guides so you can actually deploy it—even if you’ve never done it before.  **What’s in it:**  * **Detailed Tutorials & config template to eploy backend to Vercel and frontend to Cloudflare (both have free tiers)** * **Supabase for database and auth (also free tier)** * **Generate frontend client based on backend API** * Dashboard with metrics and analytics * User management and role-based access control * Sign up / sign in with OAuth * Task management with full CRUD * Pre-configured dev setup with Docker and hot reload  it’s meant to be used as a quick project starter for app developed by a single person, It followed solid backend/frontend practices, used modern tools (React 19, TypeScript, Tailwind, OpenAPI, etc.), and tried to keep the architecture clean and easy to extend.   frontend is based on this great project called shadcn-admin (https://github.com/satnaing/shadcn-admin)  If you’re trying to build and deploy a real app with no cost, this could be interesting to you. Whether you’re making a SaaS, a side project, or just want to understand the fullstack flow better, I hope this saves you some time.  Still actively improving it, so any feedback is appreciated.    **Github**  \[github-fullstack-solopreneur-template\](https://github.com/raceychan/fullstack-solopreneur-template/tree/master)",https://www.reddit.com/r/Python/comments/1l9q16q/i_built_a_fullstack_solopreneur_project_template/,Last_Difference9410,23,1749743733.0,4,/r/Python/comments/1l9q16q/i_built_a_fullstack_solopreneur_project_template/,Resource,2025-06-12 16:55:33
1l9n1pf,I cannot be the only one that hates Flask,"**EDIT: I admit I was wrong, most of what I named wasn't Flask's fault, but my Python incompetence thank you all for telling me that. And I realised the speed argument was bullshit /serious**  I like webdevelopment. I have my own website that I regularly maintain, built with svelteKit. It has a frontend (ofc) and a backend using the GitHub API.  Recently our coding teacher gave us the assignment to make a website with a function backend, but we HAD to use Flask for backend. This is because our school only taught us python, and no JavaScript. Keep in mind we had to make a regular website (without backend) before this assignment, also without teaching Javascript.  Now I have some experience with Flask, and I can safely say that I feel nothing but pure hate for it. I am not joking when I say this is the worst and most hate inducing assignment I have ever gotten from school. I asked my fellow classmates what they thought of it and I have only heared one response: ""I hate it"". Keep in mind in our school coding is not mandatory and everyone who participates does so because they chose to.  Its a combination of  * Pythons incredibly annoying indentation, * Pythons lack of semicolon use, * The slowness of both Flask and Python, * Flasks annoying syntax for making new pages, * HTML files being turned into  django-HTML, which blocks the use of normal HTML formatters which is essential for bigger projects, and also removes the normal HTML autocomplete, * Flaskforms being (in my experience) being incredibly weird, * Having to include way to many libraries, * Hard to read error messages (subjective ofc), * The availability of way better options, * and more (like my teacher easily being the worst one I currently have)  result in a hate towards Flask, and also increased my dislike of python in general.  I know that some of those are Pythons quirks and thingeys, but they do contribute so I am including them.  Please tell me that I am not the only one who hates Flask",https://www.reddit.com/r/Python/comments/1l9n1pf/i_cannot_be_the_only_one_that_hates_flask/,DefenitlyNotADolphin,0,1749736386.0,28,/r/Python/comments/1l9n1pf/i_cannot_be_the_only_one_that_hates_flask/,Discussion,2025-06-12 14:53:06
1l9furl,"What ever happened to ""Zope""?!","This is just a question out of curiosity, but back in 1999 I had to work with Python and Zope, as time progressed, I noticed that Zope is hardly if ever mentioned anywhere. Is Zope still being used? Or has it kinda fallen into obscurity? Or has it evolved in to something else ?",https://www.reddit.com/r/Python/comments/1l9furl/what_ever_happened_to_zope/,RevolutionarySeven7,135,1749711396.0,22,/r/Python/comments/1l9furl/what_ever_happened_to_zope/,Discussion,2025-06-12 07:56:36
1l9frz7,SimplePyQ - Queueing tasks in Python doesn't have to be complicated,"Hey everybody!  I just wanted to share a small library I wrote for some internal tooling that I thought could be useful for the wider community, called [SimplePyQ](https://pypi.org/project/simplepyq/).  The motivation for this was to have something minimalistic and self-contained that could handle basic task queueing without any external dependencies (such as Airflow, Redis, RabbitMQ, Celery, etc) to minimize the time and effort to get that part of a project up and running, so that I could focus on the actual things that I needed.  There's a long list of potential improvements and new features this library could have, so I wanted to get some real feedback from users to see if it's worth spending the time. You can find more information and share your ideas on our [GitHub](https://github.com/kdewald/simplepyq).  Do you have any questions? Ask away!  *TL;DR to keep the automod happy*  # What My Project Does  It's a minimalistic task queueing library with minimal external dependencies.  # Target Audience  Any kind users, ideally suitable for fast ""zero to value"" projects.  # Comparison  Much simpler to set up and use compared to Celery. Even more minimalistic with less requirements than RQ.",https://www.reddit.com/r/Python/comments/1l9frz7/simplepyq_queueing_tasks_in_python_doesnt_have_to/,kevindewald,19,1749711083.0,3,/r/Python/comments/1l9frz7/simplepyq_queueing_tasks_in_python_doesnt_have_to/,Showcase,2025-06-12 07:51:23
1l987wu,"Thursday Daily Thread: Python Careers, Courses, and Furthering Education!","# Weekly Thread: Professional Use, Jobs, and Education 🏢  Welcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**.  ---  ## How it Works:  1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles. 2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources. 3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally.  ---  ## Guidelines:  - This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar. - Keep discussions relevant to Python in the professional and educational context.    ---  ## Example Topics:  1. **Career Paths**: What kinds of roles are out there for Python developers? 2. **Certifications**: Are Python certifications worth it? 3. **Course Recommendations**: Any good advanced Python courses to recommend? 4. **Workplace Tools**: What Python libraries are indispensable in your professional work? 5. **Interview Tips**: What types of Python questions are commonly asked in interviews?  ---  Let's help each other grow in our careers and education. Happy discussing! 🌟",https://www.reddit.com/r/Python/comments/1l987wu/thursday_daily_thread_python_careers_courses_and/,AutoModerator,1,1749686432.0,0,/r/Python/comments/1l987wu/thursday_daily_thread_python_careers_courses_and/,:pythonLogo: Daily Thread,2025-06-12 01:00:32
1l95skp,Is Python really important for cybersecurity?,"I've seen some people saying that Python isn't really necessary to get started in the field, but I began learning it specifically because I plan to move into cybersecurity in the future. I’d love to hear from people already working in the area — how much does Python actually matter?",https://www.reddit.com/r/Python/comments/1l95skp/is_python_really_important_for_cybersecurity/,Wendellcesar,0,1749679899.0,9,/r/Python/comments/1l95skp/is_python_really_important_for_cybersecurity/,Discussion,2025-06-11 23:11:39
1l94mr0,[Project] I built an Open-Source WhatsApp Chatbot using Python and the Gemini AI API.,"Hey r/Python,  I wanted to share a project I've been working on: a simple but powerful AI-powered chatbot for WhatsApp, with Python at its core.  Here's the GitHub link upfront for those who want to dive in:   [https://github.com/YonkoSam/whatsapp-python-chatbot](https://github.com/YonkoSam/whatsapp-python-chatbot)  # What My Project Does  The project is an open-source Python application that acts as the ""brain"" for a WhatsApp chatbot. It listens for incoming messages, sends them to Google's Gemini AI for an intelligent response, and then replies back to the user on WhatsApp. The entire backend logic is written in Python, making it easy to customize and extend.  # Target Audience  This is primarily for **Python hobbyists, developers, and tinkerers**. It's perfect if you want to:  * Create a personal AI assistant on your phone. * Automate simple FAQs for a small community or project. * Have a fun, practical project to learn how to connect Python with external APIs (like Gemini and a WhatsApp gateway).  It's **not** designed for large-scale enterprise use, which would be better served by the official (and much more complex/expensive) WhatsApp Business API.  # Comparison to Alternatives  I built this because I saw a gap between the different existing solutions:  * **vs. The Official WhatsApp Business API:** The official API is powerful but can be very expensive and complex to get approved for and set up. My project is a lightweight, low-cost alternative ($6/month for the gateway) that's accessible to individual developers and small projects without the corporate overhead. * **vs. Other Open-Source Libraries (e.g., whatsapp-web.js):** Many open-source libraries that directly interface with WhatsApp are fantastic but can be unstable and break with every WhatsApp update. I made a conscious trade-off to use a stable, low-cost gateway API for the connection. This lets you focus on the fun part—the Python logic—instead of constantly fixing the connection. * **vs. No-Code Platforms:** No-code builders are easy but are closed-source and lock you into their ecosystem. This project is fully open-source. You have 100% control over the Python code to add any custom integration or logic you can dream of.  I'd love to get feedback from the community on the approach and any ideas for new features. Happy to answer any questions about the implementation",https://www.reddit.com/r/Python/comments/1l94mr0/project_i_built_an_opensource_whatsapp_chatbot/,samla123li,0,1749677039.0,4,/r/Python/comments/1l94mr0/project_i_built_an_opensource_whatsapp_chatbot/,Showcase,2025-06-11 22:23:59
1l8yhx5,Ugh.. truthiness. Are there other footguns to be aware of? Insight to be had?,"So today I was working with set intersections, and found myself needing to check if a given intersection was empty or not.  I started with: ``` if not set1 & set2:     return False return True ```  which I thought could be reduced to a single line, which is where I made my initial mistakes:  ``` # oops, not actually returning a boolean return set1 & set2   # oops, neither of these are coerced to boolean return set1 & set2 == True return True == set1 & set2   # stupid idea that works return not not set1 & set2  # what I should have done to start with return bool(set1 & set2)  # but maybe the right way to do it is...? return len(set1 & set2) > 0 ```  Maybe I haven't discovered the ~zen~ of python yet, but I am finding myself sort of frustrated with truthiness, and missing what I would consider semantically clear interfaces to collections that are commonly found in other languages. For example, [rust is_empty](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.is_empty), [java isEmpty()](https://docs.oracle.com/javase/8/docs/api/java/util/List.html#isEmpty--), [c++ empty()](https://cplusplus.com/reference/vector/vector/empty/), [ruby empty?](https://docs.ruby-lang.org/en/3.4/Array.html#method-i-empty-3F).  Of course there are other languages like JS and Lua without explicit isEmpty semantics, so obviously there is a spectrum here, and while I prefer the explicit approach, it's clear that this was an intentional design choice for python and for a few other languages.   Anyway, it got me thinking about the ergonomics of truthiness, and had me wondering if there are other pitfalls to watch out for, or better yet, some other way to understand the ergonomics of truthiness in python that might yield more insight into the language as a whole.  edit: fixed a logic error above ",https://www.reddit.com/r/Python/comments/1l8yhx5/ugh_truthiness_are_there_other_footguns_to_be/,jmole,0,1749662472.0,44,/r/Python/comments/1l8yhx5/ugh_truthiness_are_there_other_footguns_to_be/,Discussion,2025-06-11 18:21:12
1l8xwsc,Juvio - UV Kernel for Jupyter,"Hi everyone,  I would like to share a small open-source project that brings uv-powered ephemeral environments to Jupyter. In short, whenever you start a notebook, an isolated venv is created with dependencies stored directly within the notebook itself (PEP 723).  🔗 GitHub: [https://github.com/OKUA1/juvio](https://github.com/OKUA1/juvio) (MIT License)  **What it does**  💡 Inline Dependency Management  Install packages right from the notebook:  `%juvio install numpy pandas`  Dependencies are saved directly in the notebook as metadata (PEP 723-style), like:      # /// script     # requires-python = ""==3.10.17""     # dependencies = [     # ""numpy==2.2.5"",     # ""pandas==2.2.3""     # ]     # ///  ⚙️ Automatic Environment Setup  When the notebook is opened, Juvio installs the dependencies automatically in an ephemeral virtual environment (using uv), ensuring that the notebook runs with the correct versions of the packages and Python.  📁 Git-Friendly Format  Notebooks are converted on the fly to a script-style format using # %% markers, making diffs and version control painless:      # %%     %juvio install numpy     # %%     import numpy as np     # %%     arr = np.array([1, 2, 3])     print(arr)     # %%  **Target audience**  Mostly data scientists frequently working with notebooks.  **Comparison**  There are several projects that provide similar features to `juvio`.  juv also stores dependency metadata inside the notebook and uses uv for dependency management.  marimo stores the notebooks as plain scripts and has the ability to include dependencies in PEP 723 format.  However, to the best of my knowledge, `juvio` is the only project that creates an ephemeral environment on the kernel level. This allows you to have multiple notebooks within the same JupyterLab session, each with its own venv.",https://www.reddit.com/r/Python/comments/1l8xwsc/juvio_uv_kernel_for_jupyter/,iryna_kondr,127,1749661149.0,8,/r/Python/comments/1l8xwsc/juvio_uv_kernel_for_jupyter/,Resource,2025-06-11 17:59:09
1l8ws23,I built a Code Agent that writes python code and then live-debugs using pytests tests.,"* **What My Project Does**:    * An AI-powered coder and debugger in one place    * Use LLM to drive debugger (debugpy) in VS Code    * Documentation: [zentar.ai](http://zentar.ai/) * Github: [github.com/Zentar-Ai/zentara-code/](http://github.com/Zentar-Ai/zentara-code/) VS Code Marketplace: [marketplace.visualstudio.com/items/?itemName=ZentarAI.zentara-code](http://marketplace.visualstudio.com/items/?itemName=ZentarAI.zentara-code)    * **Target Audience**: Meant for production * **Comparison**:    * First in kind comprehensive AI-powered debugger and code in one place    * For python tests: Drive pytests tests, catch assertion errors, walk the stack , inspect variables, stack tracing.         ",https://www.reddit.com/r/Python/comments/1l8ws23/i_built_a_code_agent_that_writes_python_code_and/,bn_from_zentara,0,1749658426.0,3,/r/Python/comments/1l8ws23/i_built_a_code_agent_that_writes_python_code_and/,Showcase,2025-06-11 17:13:46
1l8mq91,Pyodbc to SQL Server using executemany or TVP?,"The datasets I'm working with would range from 100,000 rows to 2 million rows of data. With around 40 columns per row.  I'm looking to write the fastest code possible and I assume a table valued parameter passed to sql server via pyodbc would be the fastest as its less network calls and trips to sql. I've looked for comparisons with using fast\_executemany = True and cursor.executemany in pyodbc but cant seem to find any.   Anyone ever tested or know if passing data via a TVP would be alot faster than using executemany? My assumption would be yes but thought I'd ask in case anyone has tested this themselves.  ",https://www.reddit.com/r/Python/comments/1l8mq91/pyodbc_to_sql_server_using_executemany_or_tvp/,Particular-Battle513,3,1749627936.0,2,/r/Python/comments/1l8mq91/pyodbc_to_sql_server_using_executemany_or_tvp/,Discussion,2025-06-11 08:45:36
1l8kqsg,Flowguard: A minimal rate-limiting library for Python (sync + async) -- Feedback welcome!,"🚦 Flowguard – A Python rate limiter for both synchronous and asynchronous code. 🔗 https://github.com/Tapanhaz/flowguard  1. What it does: Flowguard lets you control how many operations are allowed within a time window. You can set optional burst limits and use it in both sync and async Python applications.  2. Who it's for: Developers building APIs or services that need rate limiting with minimal overhead.  3. Comparison with similar tools: Compared to aiolimiter (which is async-only and uses the leaky bucket algorithm), Flowguard supports both sync and async contexts, and allows bursting (e.g., sending all allowed requests at once). Planned: support for the leaky bucket algorithm.",https://www.reddit.com/r/Python/comments/1l8kqsg/flowguard_a_minimal_ratelimiting_library_for/,DifficultZebra1553,11,1749620029.0,14,/r/Python/comments/1l8kqsg/flowguard_a_minimal_ratelimiting_library_for/,Showcase,2025-06-11 06:33:49
1l8hdwz,[Project] Generate Beautiful Chessboard Images from FEN Strings 🧠♟️,"Hi everyone! I made a small Python library to generate beautiful, customizable chessboard images from FEN strings.     What is FEN string ?  FEN (Forsyth–Edwards Notation) is a standard way to describe a chess position using a short text string. It captures piece placement, turn, castling rights, en passant targets, and move counts — everything needed to recreate the exact state of a game.    🔗 [GitHub: chessboard-image](https://github.com/anandjoshi91/chessboard-image)  `pip install chessboard-image`  # What My Project Does  * Convert FEN to high-quality chessboard images * Support for white/black POV * Optional rank/file coordinates * Customizable themes (colors, fonts)  # Target Audience  * Developers building chess tools * Content creators and educators * Anyone needing clean board images from FEN It's lightweight, offline-friendly, and great for side projects or integrations  # Comparison  * `python-chess` supports FEN parsing and SVG rendering, but image customization is limited * Most web tools aren’t Python-native or offline-friendly * **This fills a gap**: a Python-native, customizable image generator for chessboards  Feedback and contributions are welcome! 🙌",https://www.reddit.com/r/Python/comments/1l8hdwz/project_generate_beautiful_chessboard_images_from/,Own_Piano9785,21,1749608768.0,5,/r/Python/comments/1l8hdwz/project_generate_beautiful_chessboard_images_from/,Showcase,2025-06-11 03:26:08
1l8hdw8,Using Pandas for the first time,"I’ve never really had to use Pandas as a lot of my work has just had nothing to do with using excel, mainly webscraping, I’ve tried using it today and have come across a problem where when I try to save a copy of a file, the copy ends up having across the top row in a different format from the rest of the sheet, Unamed:0 through to the furthest to the right column I’ve written in Unamed:x-1 Anyone have any idea on how I could fix this? PS I am still only really getting into python and have not had much experience with a lot of what it can do, thanks",https://www.reddit.com/r/Python/comments/1l8hdw8/using_pandas_for_the_first_time/,External-Common-4837,0,1749608766.0,21,/r/Python/comments/1l8hdw8/using_pandas_for_the_first_time/,Discussion,2025-06-11 03:26:06
1l8fwu1,Is uvloop still faster than asyncio's event loop in python3.13?,"Ladies and gentleman!     I've been trying to run a (very networking, computation and io heavy) script that is async in 90% of its functionality. so far i've been using uvloop for its claimed better performance.     Now that python 3.13's free threading is supported by the majority of libraries (and the newest cpython release) the only library that is holding me back from using the free threaded python is uvloop, since it's still not updated (and hasn't been since October 2024). I'm considering falling back on asyncio's event loop for now, just because of this.      Has anyone here ran some tests to see if uvloop is still faster than asyncio? if so, by what margin? ",https://www.reddit.com/r/Python/comments/1l8fwu1/is_uvloop_still_faster_than_asyncios_event_loop/,webshark_25,255,1749604292.0,39,/r/Python/comments/1l8fwu1/is_uvloop_still_faster_than_asyncios_event_loop/,Discussion,2025-06-11 02:11:32
1l8egg6,Wednesday Daily Thread: Beginner questions,"# Weekly Thread: Beginner Questions 🐍  Welcome to our Beginner Questions thread! Whether you're new to Python or just looking to clarify some basics, this is the thread for you.  ## How it Works:  1. **Ask Anything**: Feel free to ask any Python-related question. There are no bad questions here! 2. **Community Support**: Get answers and advice from the community. 3. **Resource Sharing**: Discover tutorials, articles, and beginner-friendly resources.  ## Guidelines:  * This thread is specifically for **beginner questions**. For more advanced queries, check out our [Advanced Questions Thread](#advanced-questions-thread-link).  ## Recommended Resources:  * If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance.  ## Example Questions:  1. **What is the difference between a list and a tuple?** 2. **How do I read a CSV file in Python?** 3. **What are Python decorators and how do I use them?** 4. **How do I install a Python package using pip?** 5. **What is a virtual environment and why should I use one?**  Let's help each other learn Python! 🌟",https://www.reddit.com/r/Python/comments/1l8egg6/wednesday_daily_thread_beginner_questions/,AutoModerator,4,1749600030.0,6,/r/Python/comments/1l8egg6/wednesday_daily_thread_beginner_questions/,:pythonLogo: Daily Thread,2025-06-11 01:00:30
1l8chj0,What version do you all use at work?,"I'm about to switch jobs and have been required to use only python 3.9 for years in order to maintain consistency within my team. In my new role I'll responsible for leading the creation of our python based infrastructure. I never really know the best term for what I do, but let's say full-stack data analytics. So, the whole process from data collection, etl, through to analysis and reporting. I most often use pandas and duckdb in my pipelines. For folks who do stuff like that, what's your go to python version? Should I stick with 3.9?  P.S. I know I can use different versions as needed in my virtual environments, but I'd rather  have a standard and note the exception where needed. ",https://www.reddit.com/r/Python/comments/1l8chj0/what_version_do_you_all_use_at_work/,donHormiga,91,1749594724.0,138,/r/Python/comments/1l8chj0/what_version_do_you_all_use_at_work/,Discussion,2025-06-10 23:32:04
1l8atti,Streamlabs Python CLI,"Hi, I've written a CLI for Streamlabs Desktop, you can use it with the Remote Control API.  [https://github.com/onyx-and-iris/slobs-cli](https://github.com/onyx-and-iris/slobs-cli)  With it you can switch scenes, start/stop stream|record + other things, check the README.",https://www.reddit.com/r/Python/comments/1l8atti/streamlabs_python_cli/,onyx_and_iris,4,1749590571.0,0,/r/Python/comments/1l8atti/streamlabs_python_cli/,Resource,2025-06-10 22:22:51
1l8af2k,Template string `repr` doesn't reconstruct template?,"Is the `repr` for template strings intended not to work as ""copy paste-able"" code? I always thought this is the ""desired"" behavior of repr (if possible). I mean, I guess t-strings have a very finicky nature, but it still seems like something that could be done.  Concretely, I can build a t-string and print a `repr` representation,          >>> value = ""this""         >>> my_template = t""value is {value}""         >>> print(repr(my_template)         Template(strings=('value is ', ''), interpolations=(Interpolation('this', 'value', None, ''),))  but I can't reconstruct it from the `repr` representation:          >>> from string.templatelib import Template, Interpolation         >>> my_template = Template(strings=('value is ', ''), interpolations=(Interpolation('this', 'value', None, ''),))         Traceback (most recent call last):             ...         TypeError: Template.__new__ only accepts *args arguments    It looks like it only needs a `kwargs` version of the constructor, or to output the repr as an interleaving input         >>> my_template = Template('value is ', Interpolation('this', 'value', None, ''), '')  # no error  Or maybe just print as a t-string      def _repr_interpolation(interpolation: Interpolation):         match interpolation:             case Interpolation(_, expr, None | """", None | """"):                 return f'{{{expr}}}'             case Interpolation(_, expr, conv, None | """"):                 return f'{{{expr}!{conv}}}'             case Interpolation(_, expr, None | """", fmt):                 return f'{{{expr}:{fmt}}}'             case Interpolation(_, expr, conv, fmt):                 return f'{{{expr}!{conv}:{fmt}}}'               def repr_template_as_t_string(template: Template) -> str:         body = """".join(             x if isinstance(x, str)              else _repr_interpolation(x)              for x in template         )         return f't""{body}""'           >>> repr_template_as_t_string(my_template)     t""value is {value}""    Here are some example of `repr` for other python types      >>> print(repr(9))     9          >>> print(repr(slice(1,2,'k')))     slice(1, 2, 'k')          >>> print(repr('hello'))     'hello'          >>> print(repr(lambda x: x))  # not really possible I guess     <function <lambda> at 0x000001B717321BC0>          >>> from dataclasses import dataclass     >>> @dataclass     class A:         a: str     >>> print(repr(A('hello')))     A(a='hello')",https://www.reddit.com/r/Python/comments/1l8af2k/template_string_repr_doesnt_reconstruct_template/,NoExpression1053,8,1749589591.0,2,/r/Python/comments/1l8af2k/template_string_repr_doesnt_reconstruct_template/,Discussion,2025-06-10 22:06:31
1l8a1c6,"Pilgram 4.0, an infinite texting based idle game / MMO RPG","Pilgram version 4.0 (i call it the annuversary edition) is a telegram bot entirely built in python that lets you play a free grimdark idle MMO RPG.  In Pilgram you can go on endless quests, fight (and catch) endless monsters, craft powerful artifacts, cast spells, join guilds & cults, find powerful weapons, go on raids with your guild & ascend to become half old-god abominations.  # What my project does  The bot provides a text based interface with wich you can play the game described above  # Target audience  **MMO RPG** & **ARPG** players will probably like it. It initially was a toy project that i started at work because i was bored but it slowly built up a sizeable coomunity, so i updated it to this day.  # Comparison  The game is kind of similar to a **MUD** (Multi User Dungeon) but it has **idle game** elements (ascensions & infinite scaling), **Diablo** style loot generation (with randomized stats & unique weapon modifiers) and some **Dark Souls** elements (grimdark world & weapons scaling off your stats).  It also has some **Pokemon** elements, you can catch every monster in the game and they all generate with different stats, they can aid you in combat and they can level up with you  # More info  How is it infinite? The secret is *AI*. Every quest, event, monster & artifact in the game is generated by AI depending on the demand of the players, so in practice you'll never run out of new stuff to see.  The interface is exclusively text based, but the command interpreter i wrote is pretty easy to integrate in other places, it could even be used as a base for a GUI if anyone has the expertise for that.  I recently released the last update for the game that added the pet system.  # Links  here's the link to the code: [https://github.com/SudoOmbro/pilgram](https://github.com/SudoOmbro/pilgram)  if you wanna try out the version i'm running on my server start a conversation with `pilgram_bot` on Telegram (as stated in the privacy notice no data about you except for your user id is stored on the server).  Enjoy!",https://www.reddit.com/r/Python/comments/1l8a1c6/pilgram_40_an_infinite_texting_based_idle_game/,LordOmbro,10,1749588696.0,0,/r/Python/comments/1l8a1c6/pilgram_40_an_infinite_texting_based_idle_game/,Showcase,2025-06-10 21:51:36
1l872q5,[Project] FileVault – A Secure File Storage CLI Tool (Compression + Encryption + TUI),"Hello Python devs,  I recently finished building **FileVault**, an Encrypted file storage tool with an interactive terminal user interface.  🎥 **Demo video**:  👉 [https://www.youtube.com/watch?v=YXFQwEj1E1k](https://www.youtube.com/watch?v=YXFQwEj1E1k)  📦 **GitHub repo**:  👉 [https://github.com/MazenYasser/file-vault-python](https://github.com/MazenYasser/file-vault-python)  ⸻  **What my project does**  	•	Lets you upload any file from your system via the terminal.  	•	Files are compressed using Zstandard (zstd).  	•	Then encrypted with a Fernet key, protected by PBKDF2 + user password.  	•	You can later download and decrypt files with just a few keypresses.  	•	It has a clean terminal UI using questionary, with  navigation, path validation, progress bars, and contextual menus.  	•	Everything is local  ⸻   **Target audience**  	•	People who spend most of their time in the terminal or enjoy TUI more than GUI (I know I do)  	•	Anyone who wants a secure and simple way to store files, even just for fun.  ⸻  **Comparisons**  This isn’t trying to be a full-blown alternative to other tools.  FileVault is:  	•	More educational and exploratory in nature.  	•	Offers a simple, guided, TUI experience.  	•	It is a side project, mainly for learning streaming I/O, encryption, config handling and modular project structure.  ⸻  **Backstory**  I watched [ThePrimeTime’s](https://www.youtube.com/@ThePrimeagen) video: [https://www.youtube.com/watch?v=UowtlZB2a70](https://www.youtube.com/watch?v=UowtlZB2a70) reacting to the article *“Be an engineer, not a frameworker.”*  That really stuck with me. So I embarked on learning lower level programming concepts, to learn the inner workings of tools I use, even though I primarily work with Django. This started with a simple goal: learn file streaming in Python by making a basic file uploader. However, I kept iterating. Features kept flowing. And out of curiosity and enthusiasm, **FileVault** was born.  ⸻  **What’s next?**  There’s still more I’d love to add:  	•	Recursive Folder encryption  	•	Password reset/recovery flow  	•	CLI-only usage with argparse or similar  	•	Action history and logs  But for now — this is the MVP. And I think I’m proud of it.  If you liked it, give it a star on GitHub!   Thanks for reading and would love any feedback!  ⸻  **PS:**  I was recently laid off, and I’m actively looking for opportunities.  If you liked the project and want to connect, feel free to DM me or find me on LinkedIn (Link in repo). I’d love to chat.  ",https://www.reddit.com/r/Python/comments/1l872q5/project_filevault_a_secure_file_storage_cli_tool/,Electric_WindGodFist,4,1749581766.0,4,/r/Python/comments/1l872q5/project_filevault_a_secure_file_storage_cli_tool/,Showcase,2025-06-10 19:56:06
1l84p2i,Built a website to train spotting the worst move in Chess,"**What My Project Does**   It’s a site and puzzle-building tool for training yourself to spot the *worst* move in a chess position. Instead of solving for the best or most accurate move, you try to find the move that completely falls apart. hangs a piece, walks into mate, or otherwise ruins the position.  The idea started as a joke, but it came from a real problem: I’m not a great chess player, and I realized my biggest issue was missing threats while focusing too much on attacking. My defensive awareness was weak. So I thought what if I trained myself to recognize how *not* to play?  It turned out to be a fun and occasionally useful way to train awareness, pattern recognition, and tactical blunder detection.  **Target Audience**   This is mostly a side project for casual and improving players, or anyone who wants a different take on chess training. It’s not meant for production-level competitive prep. Think of it more as a supplement to traditional study or just a chaotic way to enjoy tactics training.  **Comparison**   There aren’t any real alternatives I know of. Most chess training tools focus on optimal or engine-approved lines this flips that. Instead of “play like Stockfish,” it’s more like “don’t play like me in blitz at 2AM.” That’s the twist.  The project is open source, free, and will always stay free.   Code & info: [https://github.com/nedlir/worstmovepossible](https://github.com/nedlir/worstmovepossible)",https://www.reddit.com/r/Python/comments/1l84p2i/built_a_website_to_train_spotting_the_worst_move/,Comfortable-Ad-2379,23,1749576353.0,1,/r/Python/comments/1l84p2i/built_a_website_to_train_spotting_the_worst_move/,Showcase,2025-06-10 18:25:53
1l81fjc,Academic study on code debugging,"Hi everyone, I’m conducting a short experiment for my master’s thesis in Information Studies at the University of Amsterdam. I’m researching how people explore and debug code in Jupyter Notebooks.  The experiment takes around 15 minutes and must be completed on a computer or laptop (not a phone or tablet). You’ll log into a JupyterHub environment, complete a few small programming tasks, and fill out two short surveys. No advanced coding experience is required beyond basic Python, and your data will remain anonymous.  Link to participate: [https://jupyter.jupyterextension.com](https://jupyter.jupyterextension.com/) Please do not use any personal information for your username when signing up. After logging in, open the folder named “Experiment\_notebooks” and go through the notebooks in order.  Feel free to message me with any questions. I reached out to the mods and they approved the post. Thank you in advance for helping out.",https://www.reddit.com/r/Python/comments/1l81fjc/academic_study_on_code_debugging/,minne4all,10,1749568723.0,14,/r/Python/comments/1l81fjc/academic_study_on_code_debugging/,Discussion,2025-06-10 16:18:43
1l81ehp,GUI - tkinter - writing most universal UI with support of system tray,"Hi, I had prepared myself a small device that is probing a loot of things, as a part of companion program I had started writing UI for it using tkinter. Once I had started writing it for Windows I just stopped myself on system tray part.  Point of utilizing System Tray icon would be minimize to system tray and ""peak"" - hover mouse over icon to see values of probe without opening whole program to window.  I realized then that writing it for Linux would be problematic as there are split between Qt and GTK (I'm skipping rest) and they do have own way to support system tray.  Will I be safe continuing work with tkinter or better split, focus on each platform (tkinter for Windows, PyQt for KDE and PyGTK for Gnome) individually? I do know second option is just adding myself work but on the other hand I had started making GUI just for this functionality of peaking system tray.",https://www.reddit.com/r/Python/comments/1l81ehp/gui_tkinter_writing_most_universal_ui_with/,BunkerFrog,0,1749568653.0,12,/r/Python/comments/1l81ehp/gui_tkinter_writing_most_universal_ui_with/,Discussion,2025-06-10 16:17:33
1l7zz59,Traceback package for lazies,"Short background: I started python about 2 years ago and i'm enjoying very simple task with my discord bot. I feel that the traceback messages lack of information for certain types of error. So I started working on something to replace the builtin traceback for something that displays more information. My title mentions lazy, because it replaces the need for adding prints and/or try statement.  Basically, i revisited those errors:      AttributeError: I take what causes the error, then display all the sub commands. Quick example, datetime.datetime.now().dday will raise an AttributeError, but the custom traceback will show all possibilities for datetime.datetime.now(), like astimezone, ctime, date, day, hour, etc. I know python 3.10 has suggestions, but hey.  IndexError: This will take the tuple that caused the error and print all index with it's value. For example, a cur.fetchone() from Sqlite3, sometimes (or most of the times) you try row\[7\] and get the error, the custom traceback will take row and list all indexes available, no need to check the database nor to add print statements.  ValueError: This one is a bit tricky, but basically returns the original message, but adding which arguments were extra or missing. For example, if you have ""one, two, three = MyFunc()"" and that function returns 2 values, you will get which values are supposed to be received.  KeyError: That custom traceback will give the list of all values for a key. For example, ""movie\['ttitle'\]"" will return a KeyError, and the custom traceback lists all the key available for ""movie"".  FileNotFoundError: This one could be a bit spammy with big projects, but keep in mind that i don't have a lot of files. So basically this one will return all files in the path that has the same extention. For example, you try to reach configs.json while it's non existent, the custom traceback will return all .json files, so you have an idea of which file you actually need in case of typo or using the wrong name.  That is not much, but I feel like it's helping me develop a bit faster than having to think to add extra layers of debugging after an error. Feel free to give any feedbacks.",https://www.reddit.com/r/Python/comments/1l7zz59/traceback_package_for_lazies/,baltarius,1,1749565258.0,1,/r/Python/comments/1l7zz59/traceback_package_for_lazies/,Discussion,2025-06-10 15:20:58
1l7zmqh,How many tests?,"Since recently I let Cursor generate the tests for my files. Usually the AI writes quite some tests (7 different tests in my last example + plus helper methods).  How many tests do you let the AI write for you and do you prompt it specifically what tests to write? I have the impression it doesn't react to my instruction to write a ""basic"" test.",https://www.reddit.com/r/Python/comments/1l7zmqh/how_many_tests/,randomtheorx,0,1749564399.0,4,/r/Python/comments/1l7zmqh/how_many_tests/,Discussion,2025-06-10 15:06:39
1l7ym7y,pyleak: pytest-plugin to detect event loop blocking and asyncio task leaks,"A follow-up to my [previous post](https://www.reddit.com/r/Python/comments/1l2y5rz/pyleak_detect_leaked_asyncio_tasks_threads_and/), I've now added a **pytest plugin** that automatically catches these issues in your test suite:      pip install pytest-pyleak          import pytest          @pytest.mark.no_leak     async def test_my_agent():         ...  # The Problem  User A makes a request to your AI agent - expected TTFT is 600ms. But they wait 3+ seconds because User B's request (which came first) is blocking the entire event loop with a sync operation. Every new user gets queued behind the blocking request. There are a lot of discussions about optimizing AI agent performance - tweaking prompts, switching to a different model/provider, prompt caching. But there's one culprit that's often overlooked: **blocked event loops**.  # Why This Happens  Most Python agent frameworks use asyncio to handle multiple users concurrently. But it's easy to accidentally use sync operations (executing sync `def` tools in the same thread) or libraries (requests, database drivers, file I/O) that block the entire event loop. One blocking operation kills concurrency for your entire application.  # What pyleak can do (real example)  `openai-agents-python` sdk faces this exact issue where a tool defined as a `def` function blocks the event loop. We caught this thanks to `pyleak` and proposed a fix. PR: [https://github.com/openai/openai-agents-python/pull/820](https://github.com/openai/openai-agents-python/pull/820)  # Target audience  Any production-grade python project with high amount of concurrency, specially useful for AI agent frameworks and custom code since it relies heavily on asyncio.  GitHub: [https://github.com/deepankarm/pyleak](https://github.com/deepankarm/pyleak)",https://www.reddit.com/r/Python/comments/1l7ym7y/pyleak_pytestplugin_to_detect_event_loop_blocking/,deepankarmh,5,1749561768.0,0,/r/Python/comments/1l7ym7y/pyleak_pytestplugin_to_detect_event_loop_blocking/,Showcase,2025-06-10 14:22:48
1l7y8fh,Yet Another Video thumbnail Generator But It's GIF,"# What My Project Does  This is a small tool inspired by those classic thumbnail preview sheets you see in torrent metadata, except this one creates animated GIFs instead.  Example output: [https://i.imgur.com/r0QkMfj.gif](https://i.imgur.com/r0QkMfj.gif)  # Target Audience  Probably people who loves make archives.  Project: [animated-video-thumbnails](https://github.com/gokaybiz/animated-video-thumbnails)  Looking for your feedbacks!",https://www.reddit.com/r/Python/comments/1l7y8fh/yet_another_video_thumbnail_generator_but_its_gif/,tunerhd,0,1749560735.0,0,/r/Python/comments/1l7y8fh/yet_another_video_thumbnail_generator_but_its_gif/,Showcase,2025-06-10 14:05:35
1l7y0zh,I turned a thermodynamics principle into a learning algorithm - and it lands a moonlander,"# [Github project + demo videos](https://github.com/kongaskristjan/policy-annealing#policy-annealing)  **What my project does**  Physics ensures that particles usually settle in low-energy states; electrons stay near an atom's nucleus, and air molecules don't just fly off into space. I've applied an analogy of this principle to a completely different problem: teaching a neural network to safely land a lunar lander.  I did this by assigning low ""energy"" to good landing attempts (e.g. no crash, low fuel use) and high ""energy"" to poor ones. Then, using standard neural network training techniques, I enforced equations derived from thermodynamics. As a result, the lander learns to land successfully with a high probability.  **Target audience**  This is primarily a fun project for anyone interested in physics, AI, or Reinforcement Learning (RL) in general.  **Comparison to Existing Alternatives**  While most of the algorithm variants I tested aren't competitive with the current industry standard, one approach does look promising. When the derived equations are written as a regularization term, the algorithm exhibits superior stability properties compared to popular methods like Entropy Bonus.  Given that stability is a major challenge in the heavily regularized RL used to train today's LLMs, I guess it makes sense to investigate further.",https://www.reddit.com/r/Python/comments/1l7y0zh/i_turned_a_thermodynamics_principle_into_a/,kongaskristjan,99,1749560171.0,19,/r/Python/comments/1l7y0zh/i_turned_a_thermodynamics_principle_into_a/,Showcase,2025-06-10 13:56:11
1l7wwxm,Cerno - local-first AI deep research workspace,"Hello!  I’m sharing Cerno, an open-source tool for running deep, multi-step research with autonomous AI agents, right on your own machine. It uses a Django backend for orchestration and a React frontend.  # What My Project Does  Cerno is an open-source, self-hosted application that lets you to run deep, multi-step research using autonomous AI agents directly on your own machine. It provides a full-stack solution with a React frontend and a Django backend, allowing you to manage and observe complex research tasks from a user-friendly interface.  Key features include:  * **Local-First Privacy:** All data, models, and research workflows remain on your local machine, ensuring complete privacy and control. * **Transparent & Observable AI:** You can monitor step-by-step reasoning and execution, providing full transparency into the research process. * **Flexible Model Support:** Cerno is model-agnostic, supporting major providers like OpenAI and Gemini, as well as local models through Ollama. * **Safe & Structured Tool Use:** It leverages Pydantic in Agno to dynamically define tools for the AI agents. This not only generates the necessary JSON schemas for function-calling but also validates the model's outputs before execution, adding a critical layer of safety and reliability. * **Unified Python Architecture:** By building the AI orchestration and web backend entirely in Python with Django, Cerno offers a cohesive and efficient environment that simplifies development and eliminates the need for complex microservices.  # Target Audience  * **Researchers & Data Scientists** who handle sensitive information and need a secure, local environment for deep investigation. * **Developers & AI Hobbyists** who want to experiment with autonomous agents, build custom workflows, and have the flexibility to use various local or cloud-based LLMs. * **Python Developers** who will appreciate the familiar and unified Django-based architecture for easy extension and contribution.  # Comparison  Cerno distinguishes itself from existing alternatives through its unique combination of being a local, full-featured application with a robust architectural foundation.  * **vs. Cloud-Based Agent Platforms:** Where cloud platforms require you to send data to third-party services, Cerno is **local-first**. This is a fundamental differentiator, guaranteeing data privacy, eliminating vendor lock-in, and providing offline capabilities. * **vs. Other Deep Researchers:** Cerno uses a manager-researcher orchestration system to reduce token usage and optimise costs.  Screenshots:   [Main interface](https://github.com/divagr18/Cerno-Agentic-Local-Deep-Research/blob/main/screenshots/browser.png)  [Source tracking](https://github.com/divagr18/Cerno-Agentic-Local-Deep-Research/blob/main/screenshots/sources.png)  The project is actively developed and open to feedback and contributions.  Check it out on GitHub: [https://github.com/divagr18/Cerno-Agentic-Local-Deep-Research](https://www.google.com/url?sa=E&q=https%3A%2F%2Fgithub.com%2Fdivagr18%2FCerno-Agentic-Local-Deep-Research)  Would love to hear your thoughts.",https://www.reddit.com/r/Python/comments/1l7wwxm/cerno_localfirst_ai_deep_research_workspace/,MoreMouseBites,0,1749556895.0,0,/r/Python/comments/1l7wwxm/cerno_localfirst_ai_deep_research_workspace/,Showcase,2025-06-10 13:01:35
1l7usfq,"If you serve Python ASGI and/or WSGI web apps, but you don't use Granian: why?","*or put in other words: how do you pick your ASGI or WSGI server?*  In a world in which a variety of options exists, some of them being very well known like  - [gunicorn](https://github.com/benoitc/gunicorn) - [uvicorn](https://github.com/encode/uvicorn) - [uwsgi](https://github.com/unbit/uwsgi) - [hypercorn](https://github.com/pgjones/hypercorn) - [daphne](https://github.com/django/daphne)  and some others being more recent (and thus less known) like  - [granian](https://github.com/emmett-framework/granian) - [socketify](https://github.com/cirospaciari/socketify.py) - [fastwsgi](https://github.com/jamesroberts/fastwsgi) - [tremolo](https://github.com/nggit/tremolo)  what's your process in picking a server, or what do you value the most?  Do you tend to stick with *industry standards*? If so, why don't you explore more all the options? Do you just look for the most popular? Do you just use the one coming with the framework you use (or suggested by it)? Do you valuate more stability, performance or the featureset?  Do you actually care about the server, or you just don't worry about that part of the stack? If so, why?  > Disclaimer: I'm Granian maintainer. Regardless of the title – which ppl pointed out to be bad and I can't edit – I'm actually looking for honest opinions here.  *EDIT: completely rephrased the whole thing*",https://www.reddit.com/r/Python/comments/1l7usfq/if_you_serve_python_asgi_andor_wsgi_web_apps_but/,gi0baro,0,1749549542.0,41,/r/Python/comments/1l7usfq/if_you_serve_python_asgi_andor_wsgi_web_apps_but/,Discussion,2025-06-10 10:59:02
1l7l0a7,Stockstir is a Python library to get stock information from any script at no cost [CLI released!],"Hello again!  Wanted to showcase my project, Stockstir, which may be of use to many of you that want to follow stock prices freely in any script. **CLI has just been released!**  **What My Project Does**  Stockstir is an easy way to instantly gather stock data from any of your Python scripts. Not only that, but it includes other features, such as multi data gathering, anti ban, a fail-safe mechanism, random user agents, and much more.  **Target Audience**  Stockstir is for everyone that needs to gather realtime company stock info from any of their scripts. It mostly differs from any other stock related project in the way that it is simple, and doesn't rely on APIs that cost money.  **Comparison**  Stockstir differs from other methods of gathering stock data in that it is has a very simple concept behind it. It is largely a GET wrapper in the Tools class, but initial API support such as Alpha Vantage, as well as gathering much more data of a Company stock through cnbc's JSON api, are under the API class. It mostly serves as a quick and simple way to gather stock data.  You can find installation instructions and other information under the project link provided below:  Link: [Stockstir Project Link](https://github.com/PatzEdi/Stockstir)  To see the latest Changelog information, visit the [CHANGELOG.md](https://github.com/PatzEdi/Stockstir/blob/main/CHANGELOG.md) file located in the project files hosted on Github.  Here are a few examples of the different usages of Stockstir:  # Quick Usage  To easily gather a single price of a company's stock, you can do it in one line.      from stockstir import Stockstir     price = Stockstir().tools.get_single_price(""ticker/stockSymbol"")     print(price)  The above Stockstir method **get\_single\_price** is one of the most basic of the functions provided.  # New Stockstir CLI  You can now use Stockstir from the CLI!      stockstir AMZN  Where you can replace AMZN with whatever ticker/stock symbol you want. This will return the price of the stock.  # Stockstir Object Instantiation  You can instantiate Stockstir as an object, and customize certain parameters:      from stockstir import Stockstir     s = Stockstir() # Instantiate the Stockstir object, like so.     # We can also create a new Stockstir object, if for example you need certain options toggled:     s2 = Stockstir(print_output=True, random_user_agent=True, provider='cnbc')  # Stockstir Functionality, the Fail-Safe mechanism, and Providers:  I am not going to cover the entirety of Stockstir functionality here, which is why Stockstir has a [readthedocs.io](http://readthedocs.io/) documentation:  [Stockstir Documentation](https://stockstir.readthedocs.io/en/latest/)  However, basic Stockstir functionality can be described as a GET wrapper. It has *providers*, or, in other words, a website, and a regex pattern to find the price based the request made. *Providers* are a large part of Stockstir. The fail-safe mechanism chooses a new provider that works, in case it fails.  # Many Thanks  Thank you for trying out Stockstir, or even just looking into trying it! Apologies for the lack of recent updates, I am currently working on other projects.",https://www.reddit.com/r/Python/comments/1l7l0a7/stockstir_is_a_python_library_to_get_stock/,PatzEdi,24,1749514857.0,0,/r/Python/comments/1l7l0a7/stockstir_is_a_python_library_to_get_stock/,Showcase,2025-06-10 01:20:57
1l7kkp8,Tuesday Daily Thread: Advanced questions,"# Weekly Wednesday Thread: Advanced Questions 🐍  Dive deep into Python with our Advanced Questions thread! This space is reserved for questions about more advanced Python topics, frameworks, and best practices.  ## How it Works:  1. **Ask Away**: Post your advanced Python questions here. 2. **Expert Insights**: Get answers from experienced developers. 3. **Resource Pool**: Share or discover tutorials, articles, and tips.  ## Guidelines:  * This thread is for **advanced questions only**. Beginner questions are welcome in our [Daily Beginner Thread](#daily-beginner-thread-link) every Thursday. * Questions that are not advanced may be removed and redirected to the appropriate thread.  ## Recommended Resources:  * If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance.  ## Example Questions:  1. **How can you implement a custom memory allocator in Python?** 2. **What are the best practices for optimizing Cython code for heavy numerical computations?** 3. **How do you set up a multi-threaded architecture using Python's Global Interpreter Lock (GIL)?** 4. **Can you explain the intricacies of metaclasses and how they influence object-oriented design in Python?** 5. **How would you go about implementing a distributed task queue using Celery and RabbitMQ?** 6. **What are some advanced use-cases for Python's decorators?** 7. **How can you achieve real-time data streaming in Python with WebSockets?** 8. **What are the performance implications of using native Python data structures vs NumPy arrays for large-scale data?** 9. **Best practices for securing a Flask (or similar) REST API with OAuth 2.0?** 10. **What are the best practices for using Python in a microservices architecture? (..and more generally, should I even use microservices?)**  Let's deepen our Python knowledge together. Happy coding! 🌟",https://www.reddit.com/r/Python/comments/1l7kkp8/tuesday_daily_thread_advanced_questions/,AutoModerator,10,1749513630.0,4,/r/Python/comments/1l7kkp8/tuesday_daily_thread_advanced_questions/,:pythonLogo: Daily Thread,2025-06-10 01:00:30
1l7howq,A Python library to reliably detect captive portals and TLS interception (Man in the middle) attacks,"Hey all,  For a personal project (a Raspberry Pi powered hotspot + VPN), I needed to solve a problem that basic connectivity checks can't handle: how do you really know if you're on the internet, or just stuck behind a smart captive portal?  **What My Project Does**  captive-portal-detector is a Python library that provides a fast high confidence verdict on the true state of a network connection. Instead of just checking for connectivity, it determines if the network is:  1. OK: Open, secure, and free from tampering. 2. CAPTIVE: Blocked by a captive portal (e.g., a hotel login page) or actively being intercepted by a Man-in-the-Middle (MITM) attack. 3. NO\_INTERNET: Genuinely disconnected or unable to reach any trusted endpoint.  The library uses a multi-layered strategy, running several types of probes in parallel for speed and accuracy:  * HTTP Probes: Checks against standard endpoints to detect simple captive portal redirects. * Random Host Probe: Defeats ""smart"" whitelisting portals by testing against a dynamically generated, unknown domain. * Redundant, Pinned TLS Probes: Uses SPKI Public Key Pinning against two independent, user-controlled servers. This is the core feature, enabling the detection of sophisticated interception attacks used by corporate or state-level firewalls.  Out of the box, it's pinned against two redundant servers I set up (probecheck.fyi), but it's designed to be configurable. You can easily point it at your own pinned endpoints for use in your own projects.  **Target Audience**  This library is designed for developers building applications that require a high degree of network awareness and security, especially those operating in untrusted or varied environments.  While the library ships with default pinned endpoints for demonstration, the library makes it easy to point it at your own secure, redundant infrastructure.  **Alternatives**  I don't believe any specific alternatives exist that do the same thing.  OS checks (like Android/iOS popups) are simple HTTP requests designed only to detect basic login portals. They are not configurable, cannot detect whitelists, and offer no protection against or awareness of MITM attacks.  Solutions from vendors like Zscaler or Palo Alto Networks provide organization wide traffic inspection and security. They are immensely powerful but also extremely expensive and complex, requiring dedicated teams to manage.  Pypi: [https://pypi.org/project/captive-portal-detector/](https://pypi.org/project/captive-portal-detector/)  Repo: [https://gitlab.com/capdet1/captive-portal-detector/](https://gitlab.com/capdet1/captive-portal-detector/)  Advanced setup guide for the domains: [https://gitlab.com/capdet1/captive-portal-detector/-/blob/main/docs/setup\_guide.md?ref\_type=heads](https://gitlab.com/capdet1/captive-portal-detector/-/blob/main/docs/setup_guide.md?ref_type=heads)  The library has been tested on standard open networks and common captive portals (like Starbucks), but I’m especially looking for feedback from anyone who has access to more restrictive corporate or academic networks to see how it performs in the wild.",https://www.reddit.com/r/Python/comments/1l7howq/a_python_library_to_reliably_detect_captive/,Xtreme-cat,8,1749505995.0,0,/r/Python/comments/1l7howq/a_python_library_to_reliably_detect_captive/,Showcase,2025-06-09 22:53:15
1l7dwei,pyfuze 2.0.2 – A New Cross-Platform Packaging Tool for Python,"# What My Project Does  **pyfuze** packages your Python project into a **single executable**, and now supports **three distinct modes**:  |Mode|Standalone|Cross-Platform|Size|Compatibility| |:-|:-|:-|:-|:-| |**Bundle** *(default)*|✅|❌|🔴 Large|🟢 High| |**Online**|❌|✅|🟢 Small|🟢 High| |**Portable**|✅|✅|🟡 Medium|🔴 Low|  * **Bundle mode** is similar to PyInstaller's `--onefile` option. It includes Python and all dependencies, and extracts them at runtime. * **Online mode** works like bundle mode, except it **downloads Python and dependencies at runtime**, keeping the package size small. * **Portable mode** is significantly different. Based on [python.com](https://github.com/jart/cosmopolitan/wiki/python.com), it creates a truly standalone executable that **does not extract or download anything**. However, it only supports **pure Python projects and dependencies**.  # Target Audience  This tool is for Python developers who want to **package and distribute** their projects as standalone executables.  # Comparison  The most well-known tool for packaging Python projects is **PyInstaller**. Compared to it, **pyfuze** offers two additional modes:  * **Online mode** is ideal when your users have reliable network access — the final executable is only a few hundred kilobytes in size. * **Portable mode** is great for simple pure-Python projects and requires **no extraction, no downloads**, and works across platforms.  Both modes offer **cross-platform compatibility**, making **pyfuze** a flexible choice for distributing Python applications across Windows, macOS, and Linux. This is made possible by the excellent work of the [uv](https://github.com/astral-sh/uv) and [cosmopolitan](https://github.com/jart/cosmopolitan) projects.  # Note  pyfuze does **not** perform any kind of code encryption or obfuscation.  # Links  * **PyPI:** [https://pypi.org/project/pyfuze/](https://pypi.org/project/pyfuze/) * **GitHub:** [https://github.com/TanixLu/pyfuze](https://github.com/TanixLu/pyfuze)",https://www.reddit.com/r/Python/comments/1l7dwei/pyfuze_202_a_new_crossplatform_packaging_tool_for/,TanixLu,150,1749497117.0,18,/r/Python/comments/1l7dwei/pyfuze_202_a_new_crossplatform_packaging_tool_for/,Showcase,2025-06-09 20:25:17
1l7d9rl,Cloud Multi Query (CMQ) - List AWS resources simultaneusly from multiple accounts,"Hey there! I've created a Python tool to list AWS resources from multiples accounts in an easy way. It basically executes `boto3` commands simultaneusly in all the defined AWS profiles and then returns the aggregated result.  # What My Project Does  CMQ is a Python library and CLI tool that simplifies getting AWS resources across multiple accounts. Here's what makes it special:  1. **Multi-Account Management**    * Query AWS resources across multiple accounts using a single command    * Supports AWS Config profiles for easy account configuration 2. **Extensive Resource Support**    * Manage over 20+ AWS resources including:       * EC2 instances, RDS databases, Elasticache clusters       * DynamoDB tables, Kinesis streams, KMS keys       * CloudWatch metrics and logs       * And many more! 3. **Flexible Querying**    * Chain resource calls for complex queries    * Filter results using built-in functions    * Export data in various formats (list, dict, CSV)    * Real-time progress tracking with verbose output  Example of CMQ as Python library. List all RDS in all profiles:      from cmq.aws.session.profile import profile     profile().rds().list()  Example using the CLI. Create a CSV file with all lambdas running python3.10 in all defined profiles:      cmq --verbose 'profile().function().eq(""Runtime"", ""python3.10"").csv()' --output lambda.csv  An example of chained queries. This command will list all SQS queues from `account-a`, then it will load the tags of each queue and finally filter queues that have the tag `teamId=alpha`:      cmq --verbose 'profile(name=""account-a"").sqs().tags().eq(""Tags.teamId"", ""alpha"").list()'  Finally, an example to list all RDS in all enabled regions for all defined profiles:      cmq --verbose 'profile().region().rds().list()'  # Target Audience  This tool is perfect for:  * DevOps engineers managing multiple AWS accounts * Developers working with AWS infrastructure * Teams requiring cross-account resource visibility * Anyone looking to simplify AWS resource management  # Getting Started  Installation is simple:      pip install cmq  Check out the full documentation and the GitHub repo more examples and advanced usage.  * [https://ocadotechnology.github.io/cmq/](https://ocadotechnology.github.io/cmq/) * [https://github.com/ocadotechnology/cmq](https://github.com/ocadotechnology/cmq)  I hope someone out there finds it useful.   Adiós!",https://www.reddit.com/r/Python/comments/1l7d9rl/cloud_multi_query_cmq_list_aws_resources/,galimay,1,1749495680.0,2,/r/Python/comments/1l7d9rl/cloud_multi_query_cmq_list_aws_resources/,Showcase,2025-06-09 20:01:20
1l78ud9,Flowfile: Code-to-Visual. Now also Visual-to-Code: Generate polars code based on a visually,"Hi r/Python  A few weeks ago, I shared the first version of Flowfile, my open-source Python tool for turning Polars-like code into visual ETL pipelines. The top requested feature was the reverse, and I'm excited to share that it's now ready.  You can now use a visual drag-and-drop editor to build a pipeline, and Flowfile will generate a clean, standalone Python script using lazy Polars. This completes the round-trip workflow: **Code <> Visual <> Code**.  * **GitHub Repo:** [https://github.com/Edwardvaneechoud/Flowfile/](https://github.com/Edwardvaneechoud/Flowfile/) * **Quick Install:** `pip install Flowfile` * **Live Demo (GIF):**  [Demo](https://raw.githubusercontent.com/Edwardvaneechoud/Flowfile/refs/heads/main/.github/images/code-generator-gif.gif)  # What My Project Does  Flowfile is an open-source Python library that provides a bidirectional workflow for creating data pipelines. It allows you to:  1. **Write Polars-like Python code** and automatically generate an interactive, visual graph of your pipeline. 2. **(New Feature)** **Build a pipeline visually** using a drag-and-drop UI and generate a clean, standalone, high-performance Python script from it.  The entire backend is built with FastAPI and the data processing leverages Polars for its performance.      # You can write Python code like this...     import flowfile as ff     from flowfile import col, open_graph_in_editor          df = ff.from_dict({""id"": [1, 2], ""value"": [100, 200]})     result = df.filter(col(""value"") > 150)     open_graph_in_editor(result.flow_graph)          # ...and get a visual graph, which can then be turned back into a new script.  **Target Audience**  This tool is designed for production workflows but is also great for prototyping and learning. It's for:  * **Data Engineers** who want to build pipelines in code but need an easy way to visualize, document, and share them. * **Data Analysts & Scientists** who prefer a visual, low-code approach but need to hand off production-ready Python code to an engineering team. * **Teams** that want to standardize on a single tool that bridges the gap between coders and non-coders.  **Comparison**  * **vs. Pure Code (Pandas/Polars):** Flowfile adds a visual layer on top of your code with zero extra effort, making complex pipelines easier to debug and explain. * **vs. Visual ETL Tools (Alteryx, KNIME):** Flowfile isn't a black box. It gives you the full power and flexibility of Python and outputs clean code with no vendor lock-in. * **vs. Notebooks (Jupyter):** Instead of disconnected cells, Flowfile shows the entire data flow as a connected graph, making it easier to trace your logic from start to finish.  **The Long-Term Vision**  This is the first step towards a bigger goal: a tool where you can seamlessly switch between your code editor and a visual UI. The next step is to make the code generation even smarter, so it can refactor your *original* source code instead of just creating a new file.  I'd love to hear your feedback. Is this kind of bidirectional workflow useful for you or your team? Thanks for checking it out!",https://www.reddit.com/r/Python/comments/1l78ud9/flowfile_codetovisual_now_also_visualtocode/,Proof_Difficulty_434,10,1749485438.0,1,/r/Python/comments/1l78ud9/flowfile_codetovisual_now_also_visualtocode/,Showcase,2025-06-09 17:10:38
1l76m04,Building a Modern Python API with FastAPI and Azure Cosmos DB – 5-Part Video Series,Just published! A new blog post introducing a **5-part video series** on building scalable Python APIs using **FastAPI** and **Azure Cosmos DB**.  The series is hosted by developer advocate **Gwyneth Peña-Siguenza** and covers key backend concepts like:  * Structuring Pydantic models * Using FastAPI's dependency injection * Making async calls with `azure.cosmos.aio` * Executing transactional batch operations * Centralized exception handling for cleaner error management  It's a great walkthrough if you're working on async APIs or looking to scale Python apps for cloud or AI workloads.  📖 Read the full blog + watch the videos here:   [https://aka.ms/AzureCosmosDB/PythonFastAPIBlog](https://aka.ms/AzureCosmosDB/PythonFastAPIBlog)  Curious to hear your thoughts or feedback if you've tried Azure Cosmos DB with Python!,https://www.reddit.com/r/Python/comments/1l76m04/building_a_modern_python_api_with_fastapi_and/,jaydestro,7,1749480189.0,2,/r/Python/comments/1l76m04/building_a_modern_python_api_with_fastapi_and/,Tutorial,2025-06-09 15:43:09
1l72ucz,Football Tournament Maker V1.0,It is an open source web program designed by me you can modify it easily  🔹html 🔹css 🔹javascript 🔹python-flask   https://youtu.be/SMvMQYZiggQ,https://www.reddit.com/r/Python/comments/1l72ucz/football_tournament_maker_v10/,Smooth-Raisin9332,2,1749470143.0,3,/r/Python/comments/1l72ucz/football_tournament_maker_v10/,Discussion,2025-06-09 12:55:43
1l71r6i,Library for composable predicates in Python,"py-predicate is a typed Python library to create composable predicates: [https://github.com/mrijk/py-predicate](https://github.com/mrijk/py-predicate)  It let's you create composable and reusable predicates, but also for example generate values that either make a predicate evaluate to True or False (useful for testing). Plus optimisers for a given predicate and many more things.  The main difference with existing libraries is that py-predicate tries to reach a higher level of abstraction: no more for loops, if/else construct, etc. Just declare and compose predicates, and you are good to go. Downside compared to a more low-level approach is some performance loss.  Target audience are both developers (less code, more reusability) and testers (add predicates to your tests and let the generators generate True of False values).  I'm having a lot of fun (and challenges) to develop this library. Would be interested to collect feedback from developers.",https://www.reddit.com/r/Python/comments/1l71r6i/library_for_composable_predicates_in_python/,SandAlternative6026,0,1749466581.0,8,/r/Python/comments/1l71r6i/library_for_composable_predicates_in_python/,Discussion,2025-06-09 11:56:21
1l6ww94,Robyn (finally) supports Python 3.13 🎉,"For the unaware - [Robyn](https://github.com/sparckles/Robyn) is a fast, async Python web framework built on a Rust runtime.  Python 3.13 support has been one of the top requests, and after some heavy lifting (cc: `cffi` woes), it’s finally here.  Wanted to share it with folks outside the Robyn bubble.  You can check out the release at - [https://github.com/sparckles/Robyn/releases/tag/v0.68.0](https://github.com/sparckles/Robyn/releases/tag/v0.68.0)",https://www.reddit.com/r/Python/comments/1l6ww94/robyn_finally_supports_python_313/,stealthanthrax,246,1749447358.0,36,/r/Python/comments/1l6ww94/robyn_finally_supports_python_313/,News,2025-06-09 06:35:58
1l6qq6d,Monday Daily Thread: Project ideas!,"# Weekly Thread: Project Ideas 💡  Welcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you.  ## How it Works:  1. **Suggest a Project**: Comment your project idea—be it beginner-friendly or advanced. 2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code. 3. **Explore**: Looking for ideas? Check out Al Sweigart's [""The Big Book of Small Python Projects""](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration.  ## Guidelines:  * Clearly state the difficulty level. * Provide a brief description and, if possible, outline the tech stack. * Feel free to link to tutorials or resources that might help.  # Example Submissions:  ## Project Idea: Chatbot  **Difficulty**: Intermediate  **Tech Stack**: Python, NLP, Flask/FastAPI/Litestar   **Description**: Create a chatbot that can answer FAQs for a website.  **Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM)  # Project Idea: Weather Dashboard  **Difficulty**: Beginner  **Tech Stack**: HTML, CSS, JavaScript, API  **Description**: Build a dashboard that displays real-time weather information using a weather API.  **Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8)  ## Project Idea: File Organizer  **Difficulty**: Beginner  **Tech Stack**: Python, File I/O  **Description**: Create a script that organizes files in a directory into sub-folders based on file type.  **Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/)  Let's help each other grow. Happy coding! 🌟",https://www.reddit.com/r/Python/comments/1l6qq6d/monday_daily_thread_project_ideas/,AutoModerator,2,1749427229.0,2,/r/Python/comments/1l6qq6d/monday_daily_thread_project_ideas/,:pythonLogo: Daily Thread,2025-06-09 01:00:29
1l6ktgv,Pyright > Pylance,"Am I wrong? I think not. For years now Pylance has let me down, seemingly out of nowhere on multiple occasions.  Made the move to Pyright, and I couldnt be happier, 10x better.  Using VS Code.  What are the community's thoughts? Hoping to discuss the pros and cons of each.",https://www.reddit.com/r/Python/comments/1l6ktgv/pyright_pylance/,alltheapex,0,1749411413.0,15,/r/Python/comments/1l6ktgv/pyright_pylance/,Discussion,2025-06-08 20:36:53
1l6jx0p,Armin Ronacher (Flask Creator) on AI and ‘Vibe Coding’,"[https://lucumr.pocoo.org/2025/6/4/changes/](https://lucumr.pocoo.org/2025/6/4/changes/)    Armin recently left Sentry, where he has spent 10 years, and in a recent post said he's planning on starting something of his own. He talks about Cursor and Claude Code. After reading this post, it seems like he's probably going to start an AI startup or something similar?   What are your thoughts on vibe coding? Have you tried it? The pricing for Claude Code seems insane to me ($17 per month + about $3-$5 per hour of active usage, that's what I gathered).",https://www.reddit.com/r/Python/comments/1l6jx0p/armin_ronacher_flask_creator_on_ai_and_vibe_coding/,drivinmymiata,0,1749409140.0,14,/r/Python/comments/1l6jx0p/armin_ronacher_flask_creator_on_ai_and_vibe_coding/,Discussion,2025-06-08 19:59:00
1l6crs2,Why is there no python auto-instrument module for open telemetry ?,"Hi all,  I use open telemetry auto-instrumentors to get insights of my python application. These auto-instrumentors will instrument particular modules:  * [fast-api auto instrumentor](https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-fastapi) * [openai auto instrumentor](https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation-genai/opentelemetry-instrumentation-openai-v2) * etc...  As far as I understand, these modules will create spans for different events (fastapi request, openai llm call etc..), adding inputs and outputs of event as span attributes  # My question:  Why isn't there a python auto instrumentor that will create a span for each function, adding arguments and return values as attributes ?  Is it a bad idea to do such auto instrumentor ? Is it just not feasible ?   ## Edit : For those who are interested, I have coded an auto-instrumentor that will automatically create a span for the functions that are called **in user code** (not in imported modules etc...)  Check it ou there [repo](https://github.com/le-codeur-rapide/opentelemetry-instrumentation-python/tree/main/examples)",https://www.reddit.com/r/Python/comments/1l6crs2/why_is_there_no_python_autoinstrument_module_for/,PhilosopherWrong6851,86,1749391046.0,36,/r/Python/comments/1l6crs2/why_is_there_no_python_autoinstrument_module_for/,Discussion,2025-06-08 14:57:26
1l6bt6j,karva - a python test framework,"I have recently been working on making a python test framework, build in Rust.  ## What My Project Does  Similarly to pytest, karva, discovers and runs tests at given paths.  Currently, it can discover and run python tests very fast, and i am currently working on fixtures.  Personally, i have found running tests to be quite slow at times and i have already seen a massive speedup from test discovery to test running.  Using the ruff parser to find test functions and pyo3 to import and run these tests gives very good results.   ## Target Audience  I think this package can be useful for anybody who already uses pytest, with hopefully very similar syntax i aim for it to be as easy as possible to switch to using karva from pytest.  ## Comparison  While i have not *yet* implemented a lot of the useful pytest features like parameterise, fixtures and more, there is a clear speed up that can improve dev experience.  I also have to appreciate the magic that is the pytest diagnostics, currently this is not on my roadmap but eventually i will look more into improving our diagnostics.  The source code is here https://github.com/MatthewMckee4/karva  Any contributions would be greatly appreciated. Any issue reports would also be great!  Thanks",https://www.reddit.com/r/Python/comments/1l6bt6j/karva_a_python_test_framework/,Thew_4,2,1749388313.0,0,/r/Python/comments/1l6bt6j/karva_a_python_test_framework/,Showcase,2025-06-08 14:11:53
1l69934,[Project] RCPTelegram – A Telegram Bot to Remotely Control Remotely your PC,"---  [Project] RCPTelegram – A Telegram Bot to Remotely Control Your PC (Webcam, Screen, Keylogger, Pranks & More)   ---  🔧 What My Project Does  RCPTelegram is a Telegram bot that lets you remotely control your PC via chat commands. Some of the features include:  📸 Streaming your webcam and screen (via ngrok tunnels)  🖼️ Taking screenshots and webcam photos  ⌨️ Keylogger  📶 Getting saved Wi-Fi passwords  🌍 Grabbing your public IP  🔊 Setting volume and managing output devices  🎭 Pranks and other fun tools   All features are accessible from a single Telegram chat — no GUI needed.   ---  🎯 Target Audience  This is not meant for production — it's a toy/educational project designed to explore remote PC control using Python and Telegram. It’s great for learning purposes, automation experiments, or building your own personal remote assistant.   ---  ⚖️ Comparison to Existing Tools  Unlike commercial tools like TeamViewer or AnyDesk:  🟢 This works headlessly via Telegram  🛠️ Fully scriptable and open-source  🔌 Uses ngrok for quick and easy tunneling  🎉 Has playful features (like pranks) you won’t find in standard tools  🧩 You can modify and extend it however you like    ---  🗂️ Links  Bot Code: https://github.com/RiccardoZappitelli/RCPepTelegram  GUI Builder: https://github.com/RiccardoZappitelli/RCPTMaker    ---  Let me know what features you’d add or how you'd improve it. I’m also planning to split the code into multiple files soon, since I know it’s a bit messy and made with telepot right now 😅  Enjoy!  ",https://www.reddit.com/r/Python/comments/1l69934/project_rcptelegram_a_telegram_bot_to_remotely/,TipGloomy6754,11,1749379483.0,2,/r/Python/comments/1l69934/project_rcptelegram_a_telegram_bot_to_remotely/,Showcase,2025-06-08 11:44:43
1l5yvhd,Sunday Daily Thread: What's everyone working on this week?,"# Weekly Thread: What's Everyone Working On This Week? 🛠️  Hello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!  ## How it Works:  1. **Show & Tell**: Share your current projects, completed works, or future ideas. 2. **Discuss**: Get feedback, find collaborators, or just chat about your project. 3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.  ## Guidelines:  * Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome. * Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.  ## Example Shares:  1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate! 2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better. 3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!  Let's build and grow together! Share your journey and learn from others. Happy coding! 🌟",https://www.reddit.com/r/Python/comments/1l5yvhd/sunday_daily_thread_whats_everyone_working_on/,AutoModerator,7,1749340833.0,19,/r/Python/comments/1l5yvhd/sunday_daily_thread_whats_everyone_working_on/,:pythonLogo: Daily Thread,2025-06-08 01:00:33
1l5xtz5,Audited SSS (shamir shared secret) code?,"I’m currently looking for audited implementations of Shamir’s Secret Sharing (SSS). I recall coming across a dual-audited Java library on GitHub some time ago, but unfortunately, I can’t seem to locate it again.  Are there any audited Python implementations of SSS available? I've searched extensively but haven't been able to find any.  **Can anyone found some?** I'm thinking about: [https://github.com/konidev20/pyshamir](https://github.com/konidev20/pyshamir) but I don't know.",https://www.reddit.com/r/Python/comments/1l5xtz5/audited_sss_shamir_shared_secret_code/,Apprehensive_Ad_2513,7,1749337740.0,17,/r/Python/comments/1l5xtz5/audited_sss_shamir_shared_secret_code/,Discussion,2025-06-08 00:09:00
1l5ufkj,I built epub-utils: a CLI tool and Python library for inspecting EPUB files,"I've been working on a Python tool called `epub-utils` that lets you inspect and extract data from EPUB files directly from the command line. I just shipped some major updates and wanted to share what it can do.  **What My Project Does**   A command-line tool that treats EPUB files like objects you can query:      pip install epub-utils          # Quick metadata extraction     epub-utils book.epub metadata --format kv     # title: The Great Gatsby     # creator: F. Scott Fitzgerald     # language: en     # publisher: Scribner          # See the complete structure     epub-utils book.epub manifest     epub-utils book.epub spine  **Target Audience**  Developers building publishing tools that make heavy use of EPUB archives.  **Comparison**  I kept running into situations where I needed to peek inside EPUB files - checking metadata for publishing workflows, extracting content for analysis, debugging malformed files. For this I was simply using the `unzip` command but it didn't give me the structured data access I wanted for scripting. `epub-utils` instead allows you to inspect specific parts of the archive  The `files` command lets you access any file in the EPUB by its path relative to the archive root:      # List all files with compression info     epub-utils book.epub files          # Extract specific files directly     epub-utils book.epub files OEBPS/chapter1.xhtml --format plain     epub-utils book.epub files OEBPS/styles/main.css  Content extraction by manifest ID:      # Get chapter text for analysis     epub-utils book.epub content chapter1 --format plain  Pretty-printing for all XML output:      epub-utils book.epub package --pretty-print  A Python API is also available      from epub_utils import Document          doc = Document(""book.epub"")          # Direct attribute access to metadata     print(f""Title: {doc.package.metadata.title}"")     print(f""Author: {doc.package.metadata.creator}"")          # File system access     css_content = doc.get_file_by_path('OEBPS/styles/main.css')     chapter_text = doc.find_content_by_id('chapter1').to_plain()  `epub-utils` Handles both EPUB 2.0.1 and EPUB 3.0+ with proper Dublin Core metadata parsing and W3C specification adherence.  It makes it easy to  * Automate publishing pipeline validation * Debug EPUB structure issues * Extract metadata for catalogs * Quickly inspect EPUB without opening GUI apps  The tool is still in alpha (version 0.0.0a5) but the API is stabilising. I've been using it daily for EPUB work and it's saved me tons of time.  GitHub: [https://github.com/ernestofgonzalez/epub-utils](https://github.com/ernestofgonzalez/epub-utils)   PyPI: [https://pypi.org/project/epub-utils/](https://pypi.org/project/epub-utils/)  Would love feedback from anyone else working with EPUB files programmatically!",https://www.reddit.com/r/Python/comments/1l5ufkj/i_built_epubutils_a_cli_tool_and_python_library/,makeascript,13,1749328274.0,3,/r/Python/comments/1l5ufkj/i_built_epubutils_a_cli_tool_and_python_library/,Showcase,2025-06-07 21:31:14
1l5tscy,Python on tablet?,I have damaged my laptops hard disk and difficult to operate it in a remote area as there are no repair shops nearby. But i need to learn programming and dsa in 2 months. Can I code on my tablet? Any online softwares for it? ,https://www.reddit.com/r/Python/comments/1l5tscy/python_on_tablet/,West-Sale-7976,5,1749326510.0,24,/r/Python/comments/1l5tscy/python_on_tablet/,Resource,2025-06-07 21:01:50
1l5p78h,Topographic Map to 3D Model Converter,"**What my project does**  Takes an image of a topographic map and converts it into a `.obj` model.  **Target audience**   This is a pretty simple project with a lot of room to grow, so I'd say this is more of a beginner project seeing as how little time it took to produce.  **Comparison** I created this project because I couldn't really find anything else like it, so I'm not sure there is another project that does the same thing (at least, not one that I have found yet).  I created this for my Social Studies class, where I needed to have a 3D model of Israel and the Gaza strip. I plan on reusing this for future assignments as well.     However, it is kind of unfinished. As of posting this, any text in the map will be flipped on the final model, I don't have a way to upload the model to SketchFab (which is what you need in order to embed a 3D model viewer on a website), and a few other quality of life things that I'd like to implement.  But hey, I thought it turned out decently, so here is the repo:  [https://github.com/dastarruer/terrain-obj](https://github.com/dastarruer/terrain-obj)",https://www.reddit.com/r/Python/comments/1l5p78h/topographic_map_to_3d_model_converter/,Dastaguy,5,1749314590.0,0,/r/Python/comments/1l5p78h/topographic_map_to_3d_model_converter/,Showcase,2025-06-07 17:43:10
1l5m6s5,Pydantic / Celery Seamless Integration,"I've been looking for existing pydantic - celery integrations and found some that aren't seamless so I built on top of them and turned them into a 1 line integration.  [https://github.com/jwnwilson/celery\_pydantic](https://github.com/jwnwilson/celery_pydantic)  **What My Project Does**  * Allow you to use pydantic objects as celery task arguments * Allow you to return pydantic objecst from celery tasks  **Target Audience**  * Anyone who wants to use pydantic with celery.   **Comparison**  * [This blog post](https://benninger.ca/posts/celery-serializer-pydantic/) is the majority of the code above, but it requires registering each model manually, which I didn't want to do. * [Celery’s official Pydantic integration](https://docs.celeryq.dev/en/v5.5.2/userguide/tasks.html?ref=blog.dosu.dev#argument-validation-with-pydantic) only accepts plain dicts in arguments, not pydantic models. It also only returns dicts.  You can also steal this file directly if you prefer:   [https://github.com/jwnwilson/celery\_pydantic/blob/main/celery\_pydantic/serializer.py](https://github.com/jwnwilson/celery_pydantic/blob/main/celery_pydantic/serializer.py)  There are some performance improvements that can be made with better json parsers so keep that in mind if you want to use this for larger projects. Would love feedback, hope it's helpful.",https://www.reddit.com/r/Python/comments/1l5m6s5/pydantic_celery_seamless_integration/,catalyst_jw,93,1749306705.0,15,/r/Python/comments/1l5m6s5/pydantic_celery_seamless_integration/,Showcase,2025-06-07 15:31:45
1l5lkg6,A Python typing challenge,"Hey all, I am proposing here a typing challenege. I wonder if anyone has a valid solution since I haven't been able to myself. The problem is as follows:  We define a class      class Component[TInput, TOuput]: ...  the implementation is not important, just that it is parameterised by two types, `TInput` and `TOutput`.  We then define a class which processes components. This class takes in a tuple/sequence/iterable/whatever of `Component`s, as follows:          class ComponentProcessor[...]:            def __init__(self, components : tuple[...]): ...  It may be parameterised by some types, that's up to you.   The constraint is that for all components which are passed in, the output type `TOutput` of the n'th component must match the input type `TInput` of the (n + 1)'th component. This should wrap around such that the `TOutput` of the last component in the chain is equal to `TInput` of the first component in the chain.  Let me give a valid example:          a = Component[int, str](...)     b = Component[str, complex](...)     c = Component[complex, int](...)          processor = ComponentProcessor((a, b, c))  And an invalid example:           a = Component[int, float](...)     b = Component[str, complex](...)     c = Component[complex, int](...)          processor = ComponentProcessor((a, b, c))  which should yield an error since the output type of `a` is `float` which does not match the input type of `b` which is `str`.  My typing knowledge is so-so, so perhaps there are simple ways to achieve this using existing constructs, or perhaps it requires some creativity. I look forward to seeing any solutions!   An attempt, but ultimately non-functional solution is:          from __future__ import annotations     from typing import Any, overload, Unpack               class Component[TInput, TOutput]:              def __init__(self) -> None:             pass               class Builder[TInput, TCouple, TOutput]:              @classmethod         def from_components(             cls, a: Component[TInput, TCouple], b: Component[TCouple, TOutput]         ) -> Builder[TInput, TCouple, TOutput]:             return Builder((a, b))              @classmethod         def compose(             cls, a: Builder[TInput, Any, TCouple], b: Component[TCouple, TOutput]         ) -> Builder[TInput, TCouple, TOutput]:             return cls(a.components + (b,))              # two component case, all types must match         @overload         def __init__(             self,             components: tuple[                 Component[TInput, TCouple],                 Component[TCouple, TOutput],             ],         ) -> None: ...              # multi component composition         @overload         def __init__(             self,             components: tuple[                 Component[TInput, Any],                 Unpack[tuple[Component[Any, Any], ...]],                 Component[Any, TOutput],             ],         ) -> None: ...              def __init__(             self,             components: tuple[                 Component[TInput, Any],                 Unpack[tuple[Component[Any, Any], ...]],                 Component[Any, TOutput],             ],         ) -> None:             self.components = components               class ComponentProcessor[T]:              def __init__(self, components: Builder[T, Any, T]) -> None:             pass               if __name__ == ""__main__"":              a = Component[int, str]()         b = Component[str, complex]()         c = Component[complex, int]()              link_ab = Builder.from_components(a, b)         link_ac = Builder.compose(link_ab, c)              proc = ComponentProcessor(link_ac)   This will run without any warnings, but mypy just has the actual component types as `Unknown` everywhere, so if you do something that should fail it passes happily.",https://www.reddit.com/r/Python/comments/1l5lkg6/a_python_typing_challenge/,-heyhowareyou-,5,1749304979.0,39,/r/Python/comments/1l5lkg6/a_python_typing_challenge/,Discussion,2025-06-07 15:02:59
1l5ky4h,manga-sp : A simple manga scrapper,"Hi everyone!     **What My Project Does:**  I made a simple CLI application called **manga-sp** — a manga scraper that allows users to download entire volumes of manga, along with an estimated download time.  **Target Audience**:  A small project for people that want to download their favorite manga.  Comparison:  I was inspired by the app **Mihon**, which uses Kotlin-based scrapers. Since I'm more comfortable with Python, I wanted to build a Python equivalent.  # What's next:  I plan to add several customizations, such as:  * Multi-source support * More flexible download options * Enhanced path customization  Check it out here: [https://github.com/yamlof/manga-sp](https://github.com/yamlof/manga-sp)   Feedback and suggestions are welcome!",https://www.reddit.com/r/Python/comments/1l5ky4h/mangasp_a_simple_manga_scrapper/,CarryElectronic,9,1749303192.0,4,/r/Python/comments/1l5ky4h/mangasp_a_simple_manga_scrapper/,Showcase,2025-06-07 14:33:12
1l5eocl,Released real-random 0.1.1 – A module for true randomness generation based on ambient sound.,"# What my project does  This is an experimental module that works as follows:  * Records 1 to 2 seconds of audio (any sound works — even silence) * Normalizes the waveform * Converts it into a SHA-256 hash * Extracts a random number in the range `[0, 1)`  From that single number, it builds additional useful functions:  * `real_random()` → float * `real_random_int(a, b)` * `real_random_float(a, b)` * `real_random_choice(list)` * `real_random_string(n)`  All of this is based on a **physical, unpredictable source of entropy**.  # Target audience  * Experiments involving entropy, randomness, and noise * Educational contexts: demonstrating the difference between mathematical and physical randomness * Generative art or music that reacts to the sound environment * Simulations or behaviors that adapt to real-world conditions * Any project that benefits from real-world chance  # Comparison with existing modules  Unlike Python’s built-in `random`, which relies on mathematical formulas and can be seeded (making it reproducible), `real-random` **cannot be controlled or repeated**. Every execution depends on the sound in the environment at that moment. No two results are the same.  Perfect when you need **true randomness**.  # Code & Package  **PyPI:**   [https://pypi.org/project/real-random/](https://pypi.org/project/real-random/)  **GitHub**:   [https://github.com/croketillo/real-random](https://github.com/croketillo/real-random)",https://www.reddit.com/r/Python/comments/1l5eocl/released_realrandom_011_a_module_for_true/,Dismal-Hunter-3484,0,1749279593.0,23,/r/Python/comments/1l5eocl/released_realrandom_011_a_module_for_true/,Showcase,2025-06-07 07:59:53
1l5csaa,bitssh: Terminal user interface for SSH. It uses ~/.ssh/config to list and connect to hosts.,"Hi everyone 👋, I've created a tool called [bitssh](https://github.com/Mr-Sunglasses/bitssh), which creates a beautiful terminal interface of ssh config file.  Github: [https://github.com/Mr-Sunglasses/bitssh](https://github.com/Mr-Sunglasses/bitssh)  PyPi: [https://pypi.org/project/bitssh/](https://pypi.org/project/bitssh)  Demo: [https://asciinema.org/a/722363](https://asciinema.org/a/722363)  ## What My Project Does:  It parse the `~/.ssh/config` file and list all the host with there data in the beautiful table format, with an interective selection terminal UI with fuzzy search, so to connect to any host you don't need to remeber its name, you just search it and connect with it.  ## Target Audience  bitssh is very useful for sysadmins and anyone who had a lot of ssh machines and they forgot the hostname, so now they don't need to remember it, they just can search with the beautiful terminal UI interface.  You can install bitssh using pip  ``` pip install bitssh ```  If you find this project useful or it helped you, feel free to give it a star! ⭐ I'd really appreciate any feedback or contributions to make it even better! 🙏 ",https://www.reddit.com/r/Python/comments/1l5csaa/bitssh_terminal_user_interface_for_ssh_it_uses/,morpheus_jean,16,1749272223.0,12,/r/Python/comments/1l5csaa/bitssh_terminal_user_interface_for_ssh_it_uses/,Showcase,2025-06-07 05:57:03
1l5bjyr,"A simple file-sharing app built in Python with GUI, host discovery, drag-and-drop.","Hi everyone! 👋  This is a Python-based file sharing app I built as a weekend project.  **What My Project Does**  * Simple GUI for sending and receiving files over a local network * Sender side:    * Auto-host discovery (or manual IP input)    * Transfer status, drag-and-drop file support, and file integrity check using hashes * Receiver side:    * Set a listening port and destination folder to receive files * Supports multiple file transfers, works across machines (even VMs with some tweaks)  **Target Audience**  This is mainly a **learning-focused, hobby project** and is ideal for:  * Beginners learning networking with Python * People who want to understand sockets, GUI integration, and file transfers  It's not meant for production, but the logic is clean and it’s a great foundation to build on.  **Comparison**  There are plenty of file transfer tools like Snapdrop, LAN Share, and FTP servers. This app differs by:  * Being **pure Python**, no setup or third-party dependencies * Teaching-oriented — **great for learning sockets, GUIs, and local networking**  Built using **socket**, **tkinter**, and standard Python libraries. Some parts were tricky (like VM discovery), but I learned a lot along the way. Built this mostly using GitHub Copilot + debugging manually - had a lot of fun in doing so.  🔗 GitHub repo: [https://github.com/asim-builds/File-Share](https://github.com/asim-builds/File-Share)  Happy to hear any feedback or suggestions in the comments!",https://www.reddit.com/r/Python/comments/1l5bjyr/a_simple_filesharing_app_built_in_python_with_gui/,Constant-Safe-73,57,1749267842.0,5,/r/Python/comments/1l5bjyr/a_simple_filesharing_app_built_in_python_with_gui/,Showcase,2025-06-07 04:44:02
